{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Intervention Responsiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Machine Learning and preprocessing\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, roc_curve, auc, f1_score, \n",
    "    silhouette_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, ElasticNetCV\n",
    "\n",
    "# Advanced machine learning models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import (\n",
    "    pearsonr, spearmanr, kendalltau, ttest_ind, mannwhitneyu, ttest_rel, wilcoxon\n",
    ")\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Imbalanced data handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Utilities\n",
    "from itertools import combinations, chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (roc_auc_score, f1_score, accuracy_score, precision_score, \n",
    "                                recall_score, confusion_matrix, matthews_corrcoef, balanced_accuracy_score, \n",
    "                                precision_recall_curve, auc)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define threshold for responsiveness\n",
    "\n",
    "Indicate change threshold that qualifies a participant as responsive vs non-responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE RESPONSIVENESS\n",
    "\n",
    "# avg reduction in drinking occasions between active and control weeks\n",
    "def_response_drink_occasions = -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['avg_alcmost_freq', 'avg_alcmost', 'alc_norm_5_r', 'groupAtt_alc',\n",
      "       'groupAtt_binge'],\n",
      "      dtype='object')\n",
      "     Unnamed: 0       pID groupID       group_type group_gender  \\\n",
      "0             1   muri012     g2p           sports            M   \n",
      "1             2   muri016     g2p           sports            M   \n",
      "2             3   muri017     g2p           sports            M   \n",
      "3             4   muri018     g2p           sports            M   \n",
      "4             5   muri020     g2p           sports            M   \n",
      "..          ...       ...     ...              ...          ...   \n",
      "651         652  muric530    g10c  performing_arts           MF   \n",
      "652         653  muric531    g10c  performing_arts           MF   \n",
      "653         654  muric532    g10c  performing_arts           MF   \n",
      "654         655  muric533    g10c  performing_arts           MF   \n",
      "655         656  muric534    g10c  performing_arts           MF   \n",
      "\n",
      "     baseline_partial_n  baseline_socnet_n  baseline_complete_n  group_size  \\\n",
      "0                    50                 50                   44          73   \n",
      "1                    50                 50                   44          73   \n",
      "2                    50                 50                   44          73   \n",
      "3                    50                 50                   44          73   \n",
      "4                    50                 50                   44          73   \n",
      "..                  ...                ...                  ...         ...   \n",
      "651                  20                 20                   18          24   \n",
      "652                  20                 20                   18          24   \n",
      "653                  20                 20                   18          24   \n",
      "654                  20                 20                   18          24   \n",
      "655                  20                 20                   18          24   \n",
      "\n",
      "     group_identity_total  ...  X.y alc_downreg_crave  alc_react_crave  \\\n",
      "0                     NaN  ...  1.0            1.4375         1.718750   \n",
      "1                     NaN  ...  NaN               NaN              NaN   \n",
      "2                     NaN  ...  2.0            1.8750         1.541667   \n",
      "3                     NaN  ...  NaN               NaN              NaN   \n",
      "4                     NaN  ...  NaN               NaN              NaN   \n",
      "..                    ...  ...  ...               ...              ...   \n",
      "651                 5.375  ...  NaN               NaN              NaN   \n",
      "652                 2.750  ...  NaN               NaN              NaN   \n",
      "653                 5.375  ...  NaN               NaN              NaN   \n",
      "654                 6.375  ...  NaN               NaN              NaN   \n",
      "655                 3.375  ...  NaN               NaN              NaN   \n",
      "\n",
      "     alc_upreg_crave  nonalc_react_crave  alc_mindful_crave  amount_self_c  \\\n",
      "0                NaN            2.968750             1.4375      -0.193483   \n",
      "1                NaN                 NaN                NaN            NaN   \n",
      "2           2.458333            2.291667                NaN      -1.416039   \n",
      "3                NaN                 NaN                NaN      -0.193483   \n",
      "4                NaN                 NaN                NaN       1.762607   \n",
      "..               ...                 ...                ...            ...   \n",
      "651              NaN                 NaN                NaN            NaN   \n",
      "652              NaN                 NaN                NaN       0.784562   \n",
      "653              NaN                 NaN                NaN      -0.927016   \n",
      "654              NaN                 NaN                NaN      -0.193483   \n",
      "655              NaN                 NaN                NaN            NaN   \n",
      "\n",
      "     freq_self_c     age_c  race_ter  \n",
      "0      -0.711918 -2.150155     white  \n",
      "1      -1.205108 -2.150155     asian  \n",
      "2      -0.711918 -0.150155     white  \n",
      "3      -0.361912 -1.150155     white  \n",
      "4       0.465375 -0.150155     white  \n",
      "..           ...       ...       ...  \n",
      "651          NaN  1.849845     white  \n",
      "652    -0.361912 -1.150155     white  \n",
      "653    -0.361912  1.849845     white  \n",
      "654     0.465375 -2.150155     other  \n",
      "655    -1.205108 -2.150155     other  \n",
      "\n",
      "[656 rows x 387 columns]\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../../results\"\n",
    "\n",
    "data_study1 = pd.read_csv('../../SHINE/osf_study1.csv')\n",
    "data_study2 = pd.read_csv('../../SHINE/osf_study2.csv')\n",
    "\n",
    "merged_brain_behav = pd.read_csv('../../SHINE/demographics/merged_brain_behav.csv')\n",
    "data_buckets_mj = pd.read_csv('../../SHINE/intervention_df_subset_011222mj.csv', index_col=0)\n",
    "muri_baseline_scored = pd.read_csv('../../SHINE/qualtrics/1_baseline/muri_baseline_scored.csv')\n",
    "\n",
    "social_network_centralities = pd.read_csv('../../SHINE/Networks/network_centralities.csv')\n",
    "added_vars_df = pd.read_csv('../../SHINE/EMA_Round1/Yoona_PurposeAnalysis/data/old/baseline_survey.csv')\n",
    "\n",
    "b1_alcohol_self = pd.read_csv('../../SHINE/final_buckets/alcoholself_bucket280225.csv', index_col=0)\n",
    "b2_group_subjective = pd.read_csv('../../SHINE/final_buckets/subjective_grouperceptions_280225.csv', index_col=0)\n",
    "b2_group_subjective_old = pd.read_csv('/Users/fmagdalena/Documents/GitHub/shine-network-analysis/SHINE/b2_group_subjective_new.csv')\n",
    "b3_group_sociometric = pd.read_csv('../../src/responsiveness/data_social.csv')\n",
    "b4_brain = pd.read_csv('../../SHINE/final_buckets/brain_bucket_280225.csv', index_col=0)\n",
    "b5_demographic = pd.read_csv('../../SHINE/final_buckets/demographic_bucket280225.csv', index_col=0)\n",
    "b6_psychometric = pd.read_csv('../../SHINE/final_buckets/psychometrics_bucket280225.csv', index_col=0)\n",
    "\n",
    "b2_group_subjective_test = pd.read_csv('/Users/fmagdalena/Documents/GitHub/shine-network-analysis/SHINE/final_buckets/subjective_grouperceptions_test.csv')\n",
    "b2_group_subjective_test_study1 = pd.read_csv('/Users/fmagdalena/Documents/GitHub/shine-network-analysis/SHINE/final_buckets/subjective_grouperceptions_test_study1.csv')\n",
    "\n",
    "\n",
    "print(b2_group_subjective.columns)\n",
    "print(added_vars_df)\n",
    "\n",
    "# b4_brain = pd.merge(data_buckets_mj.iloc[1:].loc[:, ['SHINEID', 'segregation_resting_state_total']], b4_brain, left_on='SHINEID', right_on='id', how='inner').drop(columns=['SHINEID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_alcmost_freq    0\n",
       "avg_alcmost         0\n",
       "alc_norm_5_r        0\n",
       "groupAtt_alc        0\n",
       "groupAtt_binge      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_group_subjective.isna().sum()\n",
    "# b2_group_subjective.drop(columns=['pID', 'X', 'alc_norm_5'], inplace=True)\n",
    "\n",
    "b2_group_subjective.head()\n",
    "b2_group_subjective.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'alc_binge_efficacy', 'alc_intent_binge',\n",
       "       'DMQ_drinking_coping_motive', 'DMQ_drinking_enhancement_motive',\n",
       "       'DMQ_drinking_social_motive', 'DMQ_drinking_conformity_motive',\n",
       "       'AUQ_drink_intent', 'AUQ_drink_frequency', 'AUQ_drink_amount',\n",
       "       'alcohol_alc_att_1', 'alcohol_alc_att_2', 'DEQ_reduced_tension_exp',\n",
       "       'DEQ_increased_confidence_exp', 'DEQ_negative_consequences_exp',\n",
       "       'DEQ_reduced_cognition_exp', 'DEQ_increased_sexual_exp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_alcohol_self.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1_alcohol_self.columns\n",
    "# b1_alcohol_self = b1_alcohol_self.drop(columns=[col for col in b1_alcohol_self.columns if 'DEQ' in col])\n",
    "# b1_alcohol_self.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "groupAtt_alc        0\n",
       "groupAtt_binge      0\n",
       "avg_alcmost_freq    0\n",
       "avg_alcmost         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_group_subjective_old.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b6_psychometric.isna().sum()\n",
    "b6_psychometric = b6_psychometric[b6_psychometric['id'] != 'muri196']\n",
    "b6_psychometric = b6_psychometric[b6_psychometric['id'] != 'muri086']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "STAI_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ACS_attentionshifting",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ACS_focus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ACS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CESD_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAAS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RPI_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "IAS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PILS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ULS.4_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_clarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_goals",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_impulse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_nonacceptance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DERS_strategies",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BIS_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BIS_attention_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BIS_motor_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BIS_nonplanning",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b922631a-386e-4587-a44c-5b3388e12065",
       "rows": [
        [
         "1",
         "muri012",
         "1.45",
         "2.4",
         "2.71428571428571",
         "2.58333333333333",
         "0.9",
         "4.86666666666667",
         "2.5",
         null,
         "4.14285714285714",
         "1.75",
         "1.66666666666667",
         "2.0",
         "1.33333333333333",
         "1.61111111111111",
         "1.66666666666667",
         "1.33333333333333",
         "1.73333333333333",
         "1.5",
         "1.54545454545455",
         "2.09090909090909"
        ],
        [
         "2",
         "muri017",
         "1.8",
         "2.6",
         "2.57142857142857",
         "2.58333333333333",
         "1.1",
         "3.33333333333333",
         "3.0",
         "3.33333333333333",
         "4.57142857142857",
         "1.25",
         "2.0",
         "2.0",
         "1.0",
         "1.66666666666667",
         "2.33333333333333",
         "1.0",
         "2.36666666666667",
         "2.625",
         "2.45454545454545",
         "2.09090909090909"
        ],
        [
         "3",
         "muri034",
         "1.9",
         "2.6",
         "3.0",
         "2.83333333333333",
         "0.6",
         "4.53333333333333",
         "2.4",
         "1.33333333333333",
         "4.71428571428571",
         "0.5",
         "1.66666666666667",
         "3.33333333333333",
         "1.0",
         "2.0",
         "1.0",
         "1.33333333333333",
         "1.8",
         "1.875",
         "1.90909090909091",
         "1.63636363636364"
        ],
        [
         "4",
         "muri041",
         "2.05",
         "2.0",
         "2.14285714285714",
         "2.08333333333333",
         "1.3",
         "2.33333333333333",
         "2.6",
         "4.33333333333333",
         "3.57142857142857",
         "2.0",
         "2.33333333333333",
         "3.66666666666667",
         "1.66666666666667",
         "2.44444444444444",
         "2.0",
         "1.33333333333333",
         "2.1",
         "2.25",
         "2.09090909090909",
         "2.0"
        ],
        [
         "5",
         "muri063",
         "1.95",
         "2.4",
         "2.28571428571429",
         "2.33333333333333",
         "1.1",
         "2.93333333333333",
         "2.0",
         null,
         "3.57142857142857",
         "2.5",
         "2.66666666666667",
         "4.0",
         "1.0",
         "2.61111111111111",
         "3.0",
         "2.66666666666667",
         "1.73333333333333",
         "2.125",
         "1.72727272727273",
         "1.45454545454545"
        ],
        [
         "6",
         "muri078",
         "1.6",
         "2.2",
         "2.71428571428571",
         "2.5",
         "0.5",
         "3.66666666666667",
         "3.1",
         "2.0",
         "3.85714285714286",
         "1.75",
         "2.66666666666667",
         "1.0",
         "1.0",
         "1.77777777777778",
         "2.0",
         "1.0",
         "2.3",
         "2.25",
         "2.18181818181818",
         "2.45454545454545"
        ],
        [
         "8",
         "muri088",
         "1.8",
         "2.0",
         "2.85714285714286",
         "2.5",
         "1.1",
         "3.73333333333333",
         "2.9",
         "2.33333333333333",
         "4.0",
         "1.25",
         "2.0",
         "3.0",
         "1.33333333333333",
         "2.05555555555556",
         "2.0",
         "2.0",
         "1.96666666666667",
         "2.0",
         "1.90909090909091",
         "2.0"
        ],
        [
         "9",
         "muri091",
         "2.9",
         "1.8",
         "3.14285714285714",
         "2.58333333333333",
         "2.2",
         "2.93333333333333",
         "2.7",
         "3.33333333333333",
         "3.85714285714286",
         "1.0",
         "3.66666666666667",
         "5.0",
         "4.66666666666667",
         "4.44444444444444",
         "5.0",
         "5.0",
         "1.6",
         "1.5",
         "1.36363636363636",
         "1.90909090909091"
        ],
        [
         "10",
         "muri092",
         "2.35",
         "2.8",
         "2.42857142857143",
         "2.58333333333333",
         "1.8",
         "2.46666666666667",
         "2.8",
         "3.0",
         "3.42857142857143",
         "2.0",
         "2.33333333333333",
         "5.0",
         "1.66666666666667",
         "2.61111111111111",
         "2.0",
         "3.0",
         "2.76666666666667",
         "2.5",
         "2.18181818181818",
         "3.54545454545455"
        ],
        [
         "11",
         "muri096",
         "2.4",
         "2.2",
         "3.0",
         "2.66666666666667",
         "1.0",
         "2.8",
         "3.3",
         "2.66666666666667",
         "4.14285714285714",
         "1.25",
         "2.66666666666667",
         "3.0",
         "1.33333333333333",
         "2.77777777777778",
         "4.0",
         "2.0",
         "2.0",
         "2.125",
         "1.81818181818182",
         "2.09090909090909"
        ],
        [
         "12",
         "muri098",
         "1.4",
         "2.2",
         "1.71428571428571",
         "1.91666666666667",
         "0.3",
         "4.6",
         "2.6",
         "1.66666666666667",
         "3.85714285714286",
         "0.75",
         "1.66666666666667",
         "5.0",
         "1.66666666666667",
         "2.38888888888889",
         "1.66666666666667",
         "2.33333333333333",
         "2.03333333333333",
         "2.0",
         "2.0",
         "2.09090909090909"
        ],
        [
         "13",
         "muri101",
         "1.75",
         "3.0",
         "3.0",
         "3.0",
         "0.6",
         "3.93333333333333",
         "2.7",
         "4.66666666666667",
         "5.42857142857143",
         "1.5",
         "2.0",
         "1.66666666666667",
         "1.0",
         "1.72222222222222",
         "1.66666666666667",
         "2.0",
         "2.0",
         "1.75",
         "2.27272727272727",
         "1.90909090909091"
        ],
        [
         "14",
         "muri117",
         "1.8",
         "3.0",
         "3.14285714285714",
         "3.08333333333333",
         "1.6",
         "3.8",
         "2.8",
         "1.66666666666667",
         "4.71428571428571",
         "1.0",
         "2.33333333333333",
         "2.33333333333333",
         "1.33333333333333",
         "1.77777777777778",
         "1.66666666666667",
         "1.33333333333333",
         "2.0",
         "1.875",
         "1.90909090909091",
         "2.18181818181818"
        ],
        [
         "15",
         "muri163",
         "1.25",
         "3.0",
         "2.28571428571429",
         "2.58333333333333",
         "0.7",
         "3.6",
         "2.4",
         "1.66666666666667",
         "4.42857142857143",
         "0.75",
         "1.33333333333333",
         "1.66666666666667",
         "1.33333333333333",
         "1.55555555555556",
         "1.33333333333333",
         "1.0",
         "1.73333333333333",
         "2.25",
         "1.54545454545455",
         "1.54545454545455"
        ],
        [
         "16",
         "muri173",
         "2.3",
         "2.0",
         "2.42857142857143",
         "2.25",
         "1.0",
         "3.66666666666667",
         "2.5",
         "2.66666666666667",
         "5.0",
         "1.5",
         "2.66666666666667",
         "4.66666666666667",
         "2.0",
         "2.77777777777778",
         "2.66666666666667",
         "2.33333333333333",
         "1.83333333333333",
         "1.875",
         "1.72727272727273",
         "1.90909090909091"
        ],
        [
         "17",
         "muri186",
         "1.75",
         "3.2",
         "3.14285714285714",
         "3.16666666666667",
         "0.8",
         "4.93333333333333",
         "2.7",
         "1.33333333333333",
         "5.57142857142857",
         "1.0",
         "2.33333333333333",
         "4.0",
         "1.0",
         "2.05555555555556",
         "2.0",
         "1.66666666666667",
         "1.6",
         "1.625",
         "1.45454545454545",
         "1.72727272727273"
        ],
        [
         "19",
         "muri201",
         "1.55",
         "3.0",
         "2.71428571428571",
         "2.83333333333333",
         "0.4",
         "2.6",
         "2.1",
         "4.0",
         "4.0",
         "1.75",
         "4.0",
         "5.0",
         "2.0",
         "4.05555555555556",
         "4.33333333333333",
         "4.66666666666667",
         "1.7",
         "1.875",
         "1.81818181818182",
         "1.45454545454545"
        ],
        [
         "20",
         "muri369",
         "2.05",
         "3.6",
         "3.28571428571429",
         "3.41666666666667",
         "1.0",
         "3.2",
         "2.8",
         "3.0",
         "3.85714285714286",
         "1.25",
         "3.33333333333333",
         "2.33333333333333",
         "1.0",
         "2.22222222222222",
         "1.0",
         "2.0",
         "1.9",
         "1.875",
         "1.54545454545455",
         "2.27272727272727"
        ],
        [
         "21",
         "muri373",
         "1.95",
         "2.6",
         "3.14285714285714",
         "2.91666666666667",
         "0.7",
         "3.93333333333333",
         "3.2",
         "1.66666666666667",
         "3.14285714285714",
         "1.0",
         "1.66666666666667",
         "3.33333333333333",
         "1.66666666666667",
         "2.05555555555556",
         "2.33333333333333",
         "2.0",
         "1.93333333333333",
         "2.25",
         "1.45454545454545",
         "2.18181818181818"
        ],
        [
         "22",
         "muri389",
         "2.15",
         "2.2",
         "1.14285714285714",
         "1.58333333333333",
         "1.9",
         "1.53333333333333",
         "2.0",
         "3.66666666666667",
         "2.85714285714286",
         "1.0",
         "2.33333333333333",
         "5.0",
         "2.66666666666667",
         "3.16666666666667",
         "5.0",
         "2.33333333333333",
         "2.96666666666667",
         "3.5",
         "2.54545454545455",
         "3.0"
        ],
        [
         "23",
         "muri393",
         "1.6",
         "2.0",
         "1.57142857142857",
         "1.75",
         "1.7",
         "3.46666666666667",
         "1.9",
         "2.33333333333333",
         "4.71428571428571",
         "1.75",
         "1.66666666666667",
         "5.0",
         "2.0",
         "3.16666666666667",
         "5.0",
         "3.33333333333333",
         "2.0",
         "2.0",
         "1.54545454545455",
         "2.45454545454545"
        ],
        [
         "24",
         "muri396",
         "1.95",
         "2.0",
         "1.42857142857143",
         "1.66666666666667",
         "1.3",
         "2.93333333333333",
         "2.4",
         "4.66666666666667",
         "2.85714285714286",
         "2.0",
         "2.33333333333333",
         "3.66666666666667",
         "3.33333333333333",
         "3.38888888888889",
         "4.0",
         "4.33333333333333",
         "2.26666666666667",
         "3.0",
         "1.90909090909091",
         "2.09090909090909"
        ],
        [
         "25",
         "muri400",
         "1.95",
         "2.6",
         "2.57142857142857",
         "2.58333333333333",
         "0.6",
         "3.8",
         "1.8",
         "4.33333333333333",
         "4.0",
         "2.0",
         "1.66666666666667",
         "4.33333333333333",
         "1.33333333333333",
         "2.88888888888889",
         "4.66666666666667",
         "2.66666666666667",
         "2.06666666666667",
         "2.25",
         "2.09090909090909",
         "1.90909090909091"
        ],
        [
         "26",
         "muri404",
         "1.35",
         "2.8",
         "2.28571428571429",
         "2.5",
         "0.6",
         "3.8",
         "3.1",
         "1.0",
         "4.42857142857143",
         "0.5",
         "2.0",
         "4.0",
         "1.0",
         "2.33333333333333",
         "3.0",
         "2.0",
         "2.06666666666667",
         "2.125",
         "1.90909090909091",
         "2.18181818181818"
        ],
        [
         "27",
         "muri405",
         "2.05",
         "2.4",
         "2.42857142857143",
         "2.41666666666667",
         "1.2",
         "3.66666666666667",
         "2.7",
         "3.66666666666667",
         "3.57142857142857",
         "1.75",
         "2.0",
         "3.33333333333333",
         "2.0",
         "2.38888888888889",
         "2.33333333333333",
         "2.0",
         "2.8",
         "3.5",
         "2.36363636363636",
         "2.72727272727273"
        ],
        [
         "28",
         "muri408",
         "2.1",
         "2.2",
         "2.71428571428571",
         "2.5",
         "0.6",
         "4.46666666666667",
         "2.7",
         "2.33333333333333",
         "5.0",
         "1.75",
         "2.0",
         "2.0",
         "1.66666666666667",
         "2.16666666666667",
         "2.0",
         "2.33333333333333",
         "1.93333333333333",
         "1.75",
         "2.09090909090909",
         "1.90909090909091"
        ],
        [
         "29",
         "muri531",
         "1.9",
         "2.8",
         "3.0",
         "2.91666666666667",
         "0.5",
         "3.86666666666667",
         "2.5",
         "3.33333333333333",
         "4.42857142857143",
         "1.25",
         "2.0",
         "2.66666666666667",
         "1.0",
         "1.94444444444444",
         "2.0",
         "2.0",
         "1.83333333333333",
         "2.0",
         "1.63636363636364",
         "1.90909090909091"
        ],
        [
         "30",
         "muri542",
         "2.5",
         "2.8",
         "2.71428571428571",
         "2.75",
         "1.0",
         "2.2",
         "2.7",
         "2.0",
         "4.71428571428571",
         "2.5",
         "4.0",
         "4.33333333333333",
         "2.0",
         "2.83333333333333",
         "2.66666666666667",
         "3.0",
         "1.9",
         "2.0",
         "1.90909090909091",
         "1.81818181818182"
        ],
        [
         "31",
         "muric202",
         "2.25",
         "3.0",
         "2.57142857142857",
         "2.75",
         "1.2",
         "3.6",
         "2.4",
         "4.0",
         "4.28571428571429",
         "2.0",
         "3.0",
         "2.66666666666667",
         "1.66666666666667",
         "2.38888888888889",
         "3.0",
         "2.33333333333333",
         "2.26666666666667",
         "2.25",
         "2.54545454545455",
         "2.0"
        ],
        [
         "32",
         "muric205",
         "1.85",
         "2.0",
         "3.85714285714286",
         "3.08333333333333",
         "0.9",
         "3.26666666666667",
         "3.2",
         "1.33333333333333",
         "4.71428571428571",
         "1.0",
         "2.33333333333333",
         "4.0",
         "4.0",
         "3.38888888888889",
         "2.0",
         "3.66666666666667",
         "2.13333333333333",
         "1.875",
         "1.63636363636364",
         "2.81818181818182"
        ],
        [
         "33",
         "muric208",
         "1.85",
         "2.2",
         "3.0",
         "2.66666666666667",
         "0.8",
         "4.33333333333333",
         "2.7",
         "3.33333333333333",
         "4.0",
         "2.0",
         "2.66666666666667",
         "4.0",
         "3.0",
         "2.94444444444444",
         "3.0",
         "2.0",
         "2.06666666666667",
         "1.625",
         "1.90909090909091",
         "2.54545454545455"
        ],
        [
         "34",
         "muric210",
         "2.8",
         "2.4",
         "2.57142857142857",
         "2.5",
         "1.3",
         "3.13333333333333",
         "2.7",
         "3.66666666666667",
         "4.71428571428571",
         "1.25",
         "3.0",
         "4.0",
         "2.66666666666667",
         "2.66666666666667",
         "2.0",
         "2.66666666666667",
         "1.96666666666667",
         "2.25",
         "1.81818181818182",
         "1.90909090909091"
        ],
        [
         "35",
         "muric212",
         "1.5",
         "3.2",
         "1.85714285714286",
         "2.41666666666667",
         "1.0",
         "4.53333333333333",
         "3.3",
         "1.33333333333333",
         "4.42857142857143",
         "1.75",
         "1.66666666666667",
         "4.0",
         "3.33333333333333",
         "2.27777777777778",
         "2.0",
         "1.33333333333333",
         "2.56666666666667",
         "2.75",
         "2.54545454545455",
         "2.45454545454545"
        ],
        [
         "36",
         "muric213",
         "2.3",
         "2.4",
         "1.85714285714286",
         "2.08333333333333",
         "1.1",
         "2.6",
         "2.5",
         "3.33333333333333",
         "4.71428571428571",
         "1.5",
         "2.66666666666667",
         "4.66666666666667",
         "2.0",
         "2.83333333333333",
         "2.33333333333333",
         "3.33333333333333",
         "1.66666666666667",
         "2.0",
         "1.27272727272727",
         "1.81818181818182"
        ],
        [
         "37",
         "muric219",
         "1.7",
         "2.8",
         "3.57142857142857",
         "3.25",
         "0.5",
         "4.46666666666667",
         "3.0",
         "4.0",
         "5.0",
         "2.0",
         "1.33333333333333",
         "4.0",
         "1.33333333333333",
         "1.88888888888889",
         "2.0",
         "1.33333333333333",
         "1.9",
         "2.375",
         "1.54545454545455",
         "1.90909090909091"
        ],
        [
         "38",
         "muric224",
         "1.55",
         "2.8",
         "2.42857142857143",
         "2.58333333333333",
         "1.0",
         "4.13333333333333",
         "2.5",
         "2.66666666666667",
         "5.28571428571429",
         "0.75",
         "1.33333333333333",
         "4.66666666666667",
         "1.66666666666667",
         "2.22222222222222",
         "2.0",
         "1.33333333333333",
         "2.23333333333333",
         "2.125",
         "2.54545454545455",
         "2.0"
        ],
        [
         "39",
         "muric230",
         "2.2",
         "2.6",
         "3.0",
         "2.83333333333333",
         "0.8",
         "4.2",
         "2.7",
         "2.33333333333333",
         "4.57142857142857",
         "0.5",
         "2.0",
         "3.0",
         "1.0",
         "1.77777777777778",
         "2.0",
         "1.33333333333333",
         "1.93333333333333",
         "2.25",
         "1.81818181818182",
         "1.81818181818182"
        ],
        [
         "40",
         "muric232",
         "1.85",
         "2.4",
         "2.71428571428571",
         "2.58333333333333",
         "1.1",
         "3.73333333333333",
         "2.5",
         "3.66666666666667",
         "3.85714285714286",
         "1.75",
         "2.66666666666667",
         "4.0",
         "2.66666666666667",
         "3.05555555555556",
         "3.33333333333333",
         "3.0",
         "2.1",
         "2.375",
         "2.09090909090909",
         "1.90909090909091"
        ],
        [
         "41",
         "muric233",
         "2.0",
         "2.2",
         "2.71428571428571",
         "2.5",
         "1.0",
         "2.73333333333333",
         "3.0",
         "2.33333333333333",
         "5.0",
         "0.5",
         "3.0",
         "3.66666666666667",
         "1.0",
         "3.0",
         "3.0",
         "2.66666666666667",
         "2.13333333333333",
         "2.125",
         "2.0",
         "2.27272727272727"
        ],
        [
         "42",
         "muric234",
         "2.8",
         "2.2",
         "2.57142857142857",
         "2.41666666666667",
         "1.8",
         "2.93333333333333",
         "3.1",
         "3.33333333333333",
         "4.14285714285714",
         "2.0",
         "4.66666666666667",
         "4.66666666666667",
         "2.66666666666667",
         "4.0",
         "3.66666666666667",
         "5.0",
         "2.33333333333333",
         "3.25",
         "1.81818181818182",
         "2.18181818181818"
        ],
        [
         "43",
         "muric241",
         "1.7",
         "2.6",
         "3.0",
         "2.83333333333333",
         "0.6",
         "4.26666666666667",
         "2.5",
         "3.0",
         "4.0",
         "1.5",
         "2.0",
         "3.0",
         "1.0",
         "2.0",
         "1.33333333333333",
         "1.66666666666667",
         "2.03333333333333",
         "1.875",
         "1.90909090909091",
         "2.27272727272727"
        ],
        [
         "44",
         "muric242",
         "1.85",
         "3.2",
         "2.28571428571429",
         "2.66666666666667",
         "1.3",
         "2.93333333333333",
         "2.9",
         "1.33333333333333",
         "4.28571428571429",
         "1.0",
         "3.66666666666667",
         "4.0",
         "1.66666666666667",
         "3.33333333333333",
         "4.33333333333333",
         "3.33333333333333",
         "2.23333333333333",
         "2.625",
         "1.90909090909091",
         "2.27272727272727"
        ],
        [
         "45",
         "muric243",
         "1.7",
         "2.2",
         "2.57142857142857",
         "2.41666666666667",
         "1.0",
         "3.93333333333333",
         "2.7",
         "3.33333333333333",
         "4.0",
         "2.0",
         "2.66666666666667",
         "4.0",
         "1.33333333333333",
         "2.88888888888889",
         "4.33333333333333",
         "3.0",
         "1.86666666666667",
         "1.75",
         "1.81818181818182",
         "2.0"
        ],
        [
         "46",
         "muric244",
         "2.2",
         "1.4",
         "1.57142857142857",
         "1.5",
         "1.1",
         "3.73333333333333",
         "2.9",
         "3.33333333333333",
         "3.85714285714286",
         "2.0",
         "2.33333333333333",
         "4.66666666666667",
         "1.66666666666667",
         "2.94444444444444",
         "2.33333333333333",
         "3.33333333333333",
         "1.86666666666667",
         "2.375",
         "1.27272727272727",
         "2.09090909090909"
        ],
        [
         "47",
         "muric245",
         "1.7",
         "3.2",
         "3.0",
         "3.08333333333333",
         "0.5",
         "3.4",
         "3.2",
         "1.66666666666667",
         "4.71428571428571",
         "1.0",
         "2.33333333333333",
         "2.33333333333333",
         "1.33333333333333",
         "2.05555555555556",
         "1.0",
         "2.0",
         "2.2",
         "2.25",
         "2.45454545454545",
         "1.90909090909091"
        ],
        [
         "48",
         "muric246",
         "1.45",
         "2.4",
         "2.71428571428571",
         "2.58333333333333",
         "1.2",
         "3.73333333333333",
         "2.0",
         "3.66666666666667",
         "3.85714285714286",
         "2.5",
         "3.66666666666667",
         "3.33333333333333",
         "2.33333333333333",
         "2.88888888888889",
         "3.0",
         "2.0",
         "2.16666666666667",
         "2.5",
         "1.72727272727273",
         "2.36363636363636"
        ],
        [
         "49",
         "muric247",
         "3.05",
         "2.0",
         "1.57142857142857",
         "1.75",
         "1.7",
         "2.6",
         "2.0",
         "3.33333333333333",
         "3.0",
         "1.75",
         "2.0",
         "5.0",
         "1.0",
         "3.16666666666667",
         "4.0",
         "4.0",
         "2.46666666666667",
         "3.5",
         "1.72727272727273",
         "2.45454545454545"
        ],
        [
         "50",
         "muric249",
         "2.15",
         "2.4",
         "2.57142857142857",
         "2.5",
         "1.2",
         "3.13333333333333",
         "2.5",
         "4.0",
         "3.71428571428571",
         "1.75",
         "3.33333333333333",
         "2.66666666666667",
         "1.33333333333333",
         "2.11111111111111",
         "2.0",
         "1.66666666666667",
         "1.86666666666667",
         "2.125",
         "1.72727272727273",
         "1.81818181818182"
        ],
        [
         "51",
         "muric250",
         "2.3",
         "1.8",
         "2.14285714285714",
         "2.0",
         "2.0",
         "3.6",
         "2.8",
         "5.0",
         "4.14285714285714",
         "2.5",
         "1.66666666666667",
         "4.0",
         "2.0",
         "2.61111111111111",
         "3.33333333333333",
         "2.66666666666667",
         "2.5",
         "2.625",
         "1.90909090909091",
         "3.0"
        ],
        [
         "52",
         "muric251",
         "1.65",
         "2.4",
         "3.28571428571429",
         "2.91666666666667",
         "0.6",
         "3.26666666666667",
         "3.3",
         "4.66666666666667",
         "4.71428571428571",
         "1.5",
         "2.66666666666667",
         "2.66666666666667",
         "1.0",
         "1.83333333333333",
         "2.0",
         "1.0",
         "2.2",
         "2.375",
         "1.72727272727273",
         "2.54545454545455"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>STAI_mean</th>\n",
       "      <th>ACS_attentionshifting</th>\n",
       "      <th>ACS_focus</th>\n",
       "      <th>ACS_mean</th>\n",
       "      <th>CESD_mean</th>\n",
       "      <th>MAAS_mean</th>\n",
       "      <th>RPI_mean</th>\n",
       "      <th>IAS_mean</th>\n",
       "      <th>PILS_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>DERS_clarity</th>\n",
       "      <th>DERS_goals</th>\n",
       "      <th>DERS_impulse</th>\n",
       "      <th>DERS_mean</th>\n",
       "      <th>DERS_nonacceptance</th>\n",
       "      <th>DERS_strategies</th>\n",
       "      <th>BIS_mean</th>\n",
       "      <th>BIS_attention_total</th>\n",
       "      <th>BIS_motor_total</th>\n",
       "      <th>BIS_nonplanning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muri012</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.611111</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muri017</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muri034</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>1.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muri041</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muri063</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>muri078</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>muri088</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>muri091</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>muri092</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>3.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>muri096</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>muri098</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>muri101</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>muri117</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muri163</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>1.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>muri173</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>muri186</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>1.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>muri201</td>\n",
       "      <td>1.55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.055556</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>muri369</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>muri373</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>muri389</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>muri393</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.466667</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muri396</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>muri400</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>muri404</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>muri405</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>2.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>muri408</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>muri531</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.944444</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>muri542</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>muric202</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>muric205</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>2.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>muric208</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>muric210</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>muric212</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>muric213</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>muric219</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>muric224</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>muric230</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>muric232</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.055556</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>muric233</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>2.125</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>muric234</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.250</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>2.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>muric241</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>muric242</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>muric243</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>muric244</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>muric245</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>1.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>muric246</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>muric247</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>muric249</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>muric250</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>muric251</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  STAI_mean  ACS_attentionshifting  ACS_focus  ACS_mean  \\\n",
       "1    muri012       1.45                    2.4   2.714286  2.583333   \n",
       "2    muri017       1.80                    2.6   2.571429  2.583333   \n",
       "3    muri034       1.90                    2.6   3.000000  2.833333   \n",
       "4    muri041       2.05                    2.0   2.142857  2.083333   \n",
       "5    muri063       1.95                    2.4   2.285714  2.333333   \n",
       "6    muri078       1.60                    2.2   2.714286  2.500000   \n",
       "8    muri088       1.80                    2.0   2.857143  2.500000   \n",
       "9    muri091       2.90                    1.8   3.142857  2.583333   \n",
       "10   muri092       2.35                    2.8   2.428571  2.583333   \n",
       "11   muri096       2.40                    2.2   3.000000  2.666667   \n",
       "12   muri098       1.40                    2.2   1.714286  1.916667   \n",
       "13   muri101       1.75                    3.0   3.000000  3.000000   \n",
       "14   muri117       1.80                    3.0   3.142857  3.083333   \n",
       "15   muri163       1.25                    3.0   2.285714  2.583333   \n",
       "16   muri173       2.30                    2.0   2.428571  2.250000   \n",
       "17   muri186       1.75                    3.2   3.142857  3.166667   \n",
       "19   muri201       1.55                    3.0   2.714286  2.833333   \n",
       "20   muri369       2.05                    3.6   3.285714  3.416667   \n",
       "21   muri373       1.95                    2.6   3.142857  2.916667   \n",
       "22   muri389       2.15                    2.2   1.142857  1.583333   \n",
       "23   muri393       1.60                    2.0   1.571429  1.750000   \n",
       "24   muri396       1.95                    2.0   1.428571  1.666667   \n",
       "25   muri400       1.95                    2.6   2.571429  2.583333   \n",
       "26   muri404       1.35                    2.8   2.285714  2.500000   \n",
       "27   muri405       2.05                    2.4   2.428571  2.416667   \n",
       "28   muri408       2.10                    2.2   2.714286  2.500000   \n",
       "29   muri531       1.90                    2.8   3.000000  2.916667   \n",
       "30   muri542       2.50                    2.8   2.714286  2.750000   \n",
       "31  muric202       2.25                    3.0   2.571429  2.750000   \n",
       "32  muric205       1.85                    2.0   3.857143  3.083333   \n",
       "33  muric208       1.85                    2.2   3.000000  2.666667   \n",
       "34  muric210       2.80                    2.4   2.571429  2.500000   \n",
       "35  muric212       1.50                    3.2   1.857143  2.416667   \n",
       "36  muric213       2.30                    2.4   1.857143  2.083333   \n",
       "37  muric219       1.70                    2.8   3.571429  3.250000   \n",
       "38  muric224       1.55                    2.8   2.428571  2.583333   \n",
       "39  muric230       2.20                    2.6   3.000000  2.833333   \n",
       "40  muric232       1.85                    2.4   2.714286  2.583333   \n",
       "41  muric233       2.00                    2.2   2.714286  2.500000   \n",
       "42  muric234       2.80                    2.2   2.571429  2.416667   \n",
       "43  muric241       1.70                    2.6   3.000000  2.833333   \n",
       "44  muric242       1.85                    3.2   2.285714  2.666667   \n",
       "45  muric243       1.70                    2.2   2.571429  2.416667   \n",
       "46  muric244       2.20                    1.4   1.571429  1.500000   \n",
       "47  muric245       1.70                    3.2   3.000000  3.083333   \n",
       "48  muric246       1.45                    2.4   2.714286  2.583333   \n",
       "49  muric247       3.05                    2.0   1.571429  1.750000   \n",
       "50  muric249       2.15                    2.4   2.571429  2.500000   \n",
       "51  muric250       2.30                    1.8   2.142857  2.000000   \n",
       "52  muric251       1.65                    2.4   3.285714  2.916667   \n",
       "\n",
       "    CESD_mean  MAAS_mean  RPI_mean  IAS_mean  PILS_mean  ...  DERS_clarity  \\\n",
       "1         0.9   4.866667       2.5       NaN   4.142857  ...      1.666667   \n",
       "2         1.1   3.333333       3.0  3.333333   4.571429  ...      2.000000   \n",
       "3         0.6   4.533333       2.4  1.333333   4.714286  ...      1.666667   \n",
       "4         1.3   2.333333       2.6  4.333333   3.571429  ...      2.333333   \n",
       "5         1.1   2.933333       2.0       NaN   3.571429  ...      2.666667   \n",
       "6         0.5   3.666667       3.1  2.000000   3.857143  ...      2.666667   \n",
       "8         1.1   3.733333       2.9  2.333333   4.000000  ...      2.000000   \n",
       "9         2.2   2.933333       2.7  3.333333   3.857143  ...      3.666667   \n",
       "10        1.8   2.466667       2.8  3.000000   3.428571  ...      2.333333   \n",
       "11        1.0   2.800000       3.3  2.666667   4.142857  ...      2.666667   \n",
       "12        0.3   4.600000       2.6  1.666667   3.857143  ...      1.666667   \n",
       "13        0.6   3.933333       2.7  4.666667   5.428571  ...      2.000000   \n",
       "14        1.6   3.800000       2.8  1.666667   4.714286  ...      2.333333   \n",
       "15        0.7   3.600000       2.4  1.666667   4.428571  ...      1.333333   \n",
       "16        1.0   3.666667       2.5  2.666667   5.000000  ...      2.666667   \n",
       "17        0.8   4.933333       2.7  1.333333   5.571429  ...      2.333333   \n",
       "19        0.4   2.600000       2.1  4.000000   4.000000  ...      4.000000   \n",
       "20        1.0   3.200000       2.8  3.000000   3.857143  ...      3.333333   \n",
       "21        0.7   3.933333       3.2  1.666667   3.142857  ...      1.666667   \n",
       "22        1.9   1.533333       2.0  3.666667   2.857143  ...      2.333333   \n",
       "23        1.7   3.466667       1.9  2.333333   4.714286  ...      1.666667   \n",
       "24        1.3   2.933333       2.4  4.666667   2.857143  ...      2.333333   \n",
       "25        0.6   3.800000       1.8  4.333333   4.000000  ...      1.666667   \n",
       "26        0.6   3.800000       3.1  1.000000   4.428571  ...      2.000000   \n",
       "27        1.2   3.666667       2.7  3.666667   3.571429  ...      2.000000   \n",
       "28        0.6   4.466667       2.7  2.333333   5.000000  ...      2.000000   \n",
       "29        0.5   3.866667       2.5  3.333333   4.428571  ...      2.000000   \n",
       "30        1.0   2.200000       2.7  2.000000   4.714286  ...      4.000000   \n",
       "31        1.2   3.600000       2.4  4.000000   4.285714  ...      3.000000   \n",
       "32        0.9   3.266667       3.2  1.333333   4.714286  ...      2.333333   \n",
       "33        0.8   4.333333       2.7  3.333333   4.000000  ...      2.666667   \n",
       "34        1.3   3.133333       2.7  3.666667   4.714286  ...      3.000000   \n",
       "35        1.0   4.533333       3.3  1.333333   4.428571  ...      1.666667   \n",
       "36        1.1   2.600000       2.5  3.333333   4.714286  ...      2.666667   \n",
       "37        0.5   4.466667       3.0  4.000000   5.000000  ...      1.333333   \n",
       "38        1.0   4.133333       2.5  2.666667   5.285714  ...      1.333333   \n",
       "39        0.8   4.200000       2.7  2.333333   4.571429  ...      2.000000   \n",
       "40        1.1   3.733333       2.5  3.666667   3.857143  ...      2.666667   \n",
       "41        1.0   2.733333       3.0  2.333333   5.000000  ...      3.000000   \n",
       "42        1.8   2.933333       3.1  3.333333   4.142857  ...      4.666667   \n",
       "43        0.6   4.266667       2.5  3.000000   4.000000  ...      2.000000   \n",
       "44        1.3   2.933333       2.9  1.333333   4.285714  ...      3.666667   \n",
       "45        1.0   3.933333       2.7  3.333333   4.000000  ...      2.666667   \n",
       "46        1.1   3.733333       2.9  3.333333   3.857143  ...      2.333333   \n",
       "47        0.5   3.400000       3.2  1.666667   4.714286  ...      2.333333   \n",
       "48        1.2   3.733333       2.0  3.666667   3.857143  ...      3.666667   \n",
       "49        1.7   2.600000       2.0  3.333333   3.000000  ...      2.000000   \n",
       "50        1.2   3.133333       2.5  4.000000   3.714286  ...      3.333333   \n",
       "51        2.0   3.600000       2.8  5.000000   4.142857  ...      1.666667   \n",
       "52        0.6   3.266667       3.3  4.666667   4.714286  ...      2.666667   \n",
       "\n",
       "    DERS_goals  DERS_impulse  DERS_mean  DERS_nonacceptance  DERS_strategies  \\\n",
       "1     2.000000      1.333333   1.611111            1.666667         1.333333   \n",
       "2     2.000000      1.000000   1.666667            2.333333         1.000000   \n",
       "3     3.333333      1.000000   2.000000            1.000000         1.333333   \n",
       "4     3.666667      1.666667   2.444444            2.000000         1.333333   \n",
       "5     4.000000      1.000000   2.611111            3.000000         2.666667   \n",
       "6     1.000000      1.000000   1.777778            2.000000         1.000000   \n",
       "8     3.000000      1.333333   2.055556            2.000000         2.000000   \n",
       "9     5.000000      4.666667   4.444444            5.000000         5.000000   \n",
       "10    5.000000      1.666667   2.611111            2.000000         3.000000   \n",
       "11    3.000000      1.333333   2.777778            4.000000         2.000000   \n",
       "12    5.000000      1.666667   2.388889            1.666667         2.333333   \n",
       "13    1.666667      1.000000   1.722222            1.666667         2.000000   \n",
       "14    2.333333      1.333333   1.777778            1.666667         1.333333   \n",
       "15    1.666667      1.333333   1.555556            1.333333         1.000000   \n",
       "16    4.666667      2.000000   2.777778            2.666667         2.333333   \n",
       "17    4.000000      1.000000   2.055556            2.000000         1.666667   \n",
       "19    5.000000      2.000000   4.055556            4.333333         4.666667   \n",
       "20    2.333333      1.000000   2.222222            1.000000         2.000000   \n",
       "21    3.333333      1.666667   2.055556            2.333333         2.000000   \n",
       "22    5.000000      2.666667   3.166667            5.000000         2.333333   \n",
       "23    5.000000      2.000000   3.166667            5.000000         3.333333   \n",
       "24    3.666667      3.333333   3.388889            4.000000         4.333333   \n",
       "25    4.333333      1.333333   2.888889            4.666667         2.666667   \n",
       "26    4.000000      1.000000   2.333333            3.000000         2.000000   \n",
       "27    3.333333      2.000000   2.388889            2.333333         2.000000   \n",
       "28    2.000000      1.666667   2.166667            2.000000         2.333333   \n",
       "29    2.666667      1.000000   1.944444            2.000000         2.000000   \n",
       "30    4.333333      2.000000   2.833333            2.666667         3.000000   \n",
       "31    2.666667      1.666667   2.388889            3.000000         2.333333   \n",
       "32    4.000000      4.000000   3.388889            2.000000         3.666667   \n",
       "33    4.000000      3.000000   2.944444            3.000000         2.000000   \n",
       "34    4.000000      2.666667   2.666667            2.000000         2.666667   \n",
       "35    4.000000      3.333333   2.277778            2.000000         1.333333   \n",
       "36    4.666667      2.000000   2.833333            2.333333         3.333333   \n",
       "37    4.000000      1.333333   1.888889            2.000000         1.333333   \n",
       "38    4.666667      1.666667   2.222222            2.000000         1.333333   \n",
       "39    3.000000      1.000000   1.777778            2.000000         1.333333   \n",
       "40    4.000000      2.666667   3.055556            3.333333         3.000000   \n",
       "41    3.666667      1.000000   3.000000            3.000000         2.666667   \n",
       "42    4.666667      2.666667   4.000000            3.666667         5.000000   \n",
       "43    3.000000      1.000000   2.000000            1.333333         1.666667   \n",
       "44    4.000000      1.666667   3.333333            4.333333         3.333333   \n",
       "45    4.000000      1.333333   2.888889            4.333333         3.000000   \n",
       "46    4.666667      1.666667   2.944444            2.333333         3.333333   \n",
       "47    2.333333      1.333333   2.055556            1.000000         2.000000   \n",
       "48    3.333333      2.333333   2.888889            3.000000         2.000000   \n",
       "49    5.000000      1.000000   3.166667            4.000000         4.000000   \n",
       "50    2.666667      1.333333   2.111111            2.000000         1.666667   \n",
       "51    4.000000      2.000000   2.611111            3.333333         2.666667   \n",
       "52    2.666667      1.000000   1.833333            2.000000         1.000000   \n",
       "\n",
       "    BIS_mean  BIS_attention_total  BIS_motor_total  BIS_nonplanning  \n",
       "1   1.733333                1.500         1.545455         2.090909  \n",
       "2   2.366667                2.625         2.454545         2.090909  \n",
       "3   1.800000                1.875         1.909091         1.636364  \n",
       "4   2.100000                2.250         2.090909         2.000000  \n",
       "5   1.733333                2.125         1.727273         1.454545  \n",
       "6   2.300000                2.250         2.181818         2.454545  \n",
       "8   1.966667                2.000         1.909091         2.000000  \n",
       "9   1.600000                1.500         1.363636         1.909091  \n",
       "10  2.766667                2.500         2.181818         3.545455  \n",
       "11  2.000000                2.125         1.818182         2.090909  \n",
       "12  2.033333                2.000         2.000000         2.090909  \n",
       "13  2.000000                1.750         2.272727         1.909091  \n",
       "14  2.000000                1.875         1.909091         2.181818  \n",
       "15  1.733333                2.250         1.545455         1.545455  \n",
       "16  1.833333                1.875         1.727273         1.909091  \n",
       "17  1.600000                1.625         1.454545         1.727273  \n",
       "19  1.700000                1.875         1.818182         1.454545  \n",
       "20  1.900000                1.875         1.545455         2.272727  \n",
       "21  1.933333                2.250         1.454545         2.181818  \n",
       "22  2.966667                3.500         2.545455         3.000000  \n",
       "23  2.000000                2.000         1.545455         2.454545  \n",
       "24  2.266667                3.000         1.909091         2.090909  \n",
       "25  2.066667                2.250         2.090909         1.909091  \n",
       "26  2.066667                2.125         1.909091         2.181818  \n",
       "27  2.800000                3.500         2.363636         2.727273  \n",
       "28  1.933333                1.750         2.090909         1.909091  \n",
       "29  1.833333                2.000         1.636364         1.909091  \n",
       "30  1.900000                2.000         1.909091         1.818182  \n",
       "31  2.266667                2.250         2.545455         2.000000  \n",
       "32  2.133333                1.875         1.636364         2.818182  \n",
       "33  2.066667                1.625         1.909091         2.545455  \n",
       "34  1.966667                2.250         1.818182         1.909091  \n",
       "35  2.566667                2.750         2.545455         2.454545  \n",
       "36  1.666667                2.000         1.272727         1.818182  \n",
       "37  1.900000                2.375         1.545455         1.909091  \n",
       "38  2.233333                2.125         2.545455         2.000000  \n",
       "39  1.933333                2.250         1.818182         1.818182  \n",
       "40  2.100000                2.375         2.090909         1.909091  \n",
       "41  2.133333                2.125         2.000000         2.272727  \n",
       "42  2.333333                3.250         1.818182         2.181818  \n",
       "43  2.033333                1.875         1.909091         2.272727  \n",
       "44  2.233333                2.625         1.909091         2.272727  \n",
       "45  1.866667                1.750         1.818182         2.000000  \n",
       "46  1.866667                2.375         1.272727         2.090909  \n",
       "47  2.200000                2.250         2.454545         1.909091  \n",
       "48  2.166667                2.500         1.727273         2.363636  \n",
       "49  2.466667                3.500         1.727273         2.454545  \n",
       "50  1.866667                2.125         1.727273         1.818182  \n",
       "51  2.500000                2.625         1.909091         3.000000  \n",
       "52  2.200000                2.375         1.727273         2.545455  \n",
       "\n",
       "[50 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b6_psychometric.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b6_psychometric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "drinks_number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "active_week",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "signal_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alc_responses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "social_weekend",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "39fe983a-8cad-4885-bc96-7386d06b8ee0",
       "rows": [
        [
         "0",
         "1",
         "0.0",
         "control",
         "mindful",
         "1",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "1",
         "2",
         "0.0",
         "active",
         "mindful",
         "2",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "2",
         "3",
         "0.0",
         "active",
         "mindful",
         "3",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "3",
         "4",
         "0.0",
         "active",
         "mindful",
         "4",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "4",
         "5",
         "0.0",
         "active",
         "mindful",
         "5",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "5",
         "6",
         "0.0",
         "active",
         "mindful",
         "6",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "6",
         "7",
         "0.0",
         "active",
         "mindful",
         "7",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "7",
         "8",
         "0.0",
         "active",
         "mindful",
         "8",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "8",
         "9",
         "0.0",
         "active",
         "mindful",
         "9",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "9",
         "10",
         "0.0",
         "active",
         "mindful",
         "10",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "10",
         "11",
         "0.0",
         "active",
         "mindful",
         "11",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "11",
         "12",
         "0.0",
         "active",
         "mindful",
         "12",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "12",
         "13",
         "0.0",
         "active",
         "mindful",
         "13",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "13",
         "14",
         "0.0",
         "active",
         "mindful",
         "14",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "14",
         "15",
         null,
         "active",
         "mindful",
         "15",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "15",
         "16",
         "0.0",
         "control",
         "mindful",
         "16",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "16",
         "17",
         "0.0",
         "control",
         "mindful",
         "17",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "17",
         "18",
         "0.0",
         "control",
         "mindful",
         "18",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "18",
         "19",
         "0.0",
         "control",
         "mindful",
         "19",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "19",
         "20",
         "0.0",
         "control",
         "mindful",
         "20",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "20",
         "21",
         "0.0",
         "control",
         "mindful",
         "21",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "21",
         "22",
         "0.0",
         "control",
         "mindful",
         "22",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "22",
         "23",
         "0.0",
         "control",
         "mindful",
         "23",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "23",
         "24",
         "0.0",
         "control",
         "mindful",
         "24",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "24",
         "25",
         "0.0",
         "control",
         "mindful",
         "25",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "25",
         "26",
         "0.0",
         "control",
         "mindful",
         "26",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "26",
         "27",
         "0.0",
         "control",
         "mindful",
         "27",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "27",
         "28",
         "2.0",
         "control",
         "mindful",
         "28",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "28",
         "29",
         "0.0",
         "control",
         "mindful",
         "29",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "29",
         "30",
         "0.0",
         "active",
         "mindful",
         "30",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "30",
         "31",
         "0.0",
         "active",
         "mindful",
         "31",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "31",
         "32",
         "0.0",
         "active",
         "mindful",
         "32",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "32",
         "33",
         "0.0",
         "active",
         "mindful",
         "33",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "33",
         "34",
         "0.0",
         "active",
         "mindful",
         "34",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "34",
         "35",
         "0.0",
         "active",
         "mindful",
         "35",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "35",
         "36",
         "0.0",
         "active",
         "mindful",
         "36",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "36",
         "37",
         "1.0",
         "active",
         "mindful",
         "37",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "37",
         "38",
         "0.0",
         "active",
         "mindful",
         "38",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "38",
         "39",
         "0.0",
         "active",
         "mindful",
         "39",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "39",
         "40",
         "0.0",
         "active",
         "mindful",
         "40",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "40",
         "41",
         "0.0",
         "active",
         "mindful",
         "41",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "41",
         "42",
         "0.0",
         "active",
         "mindful",
         "42",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "42",
         "43",
         "0.0",
         "active",
         "mindful",
         "43",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "43",
         "44",
         "0.0",
         "control",
         "mindful",
         "44",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "44",
         "45",
         "0.0",
         "control",
         "mindful",
         "45",
         "53",
         "Weekend",
         "g2p",
         "muri012"
        ],
        [
         "45",
         "46",
         "0.0",
         "control",
         "mindful",
         "46",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "46",
         "47",
         "0.0",
         "control",
         "mindful",
         "47",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "47",
         "48",
         null,
         "control",
         "mindful",
         "48",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "48",
         "49",
         "0.0",
         "control",
         "mindful",
         "49",
         "53",
         "Week",
         "g2p",
         "muri012"
        ],
        [
         "49",
         "50",
         "0.0",
         "control",
         "mindful",
         "50",
         "53",
         "Week",
         "g2p",
         "muri012"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 18201
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drinks_number</th>\n",
       "      <th>active_week</th>\n",
       "      <th>condition</th>\n",
       "      <th>signal_count</th>\n",
       "      <th>alc_responses</th>\n",
       "      <th>social_weekend</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18196</th>\n",
       "      <td>12149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18197</th>\n",
       "      <td>12150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18198</th>\n",
       "      <td>12151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18199</th>\n",
       "      <td>12152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18200</th>\n",
       "      <td>12153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18201 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  drinks_number active_week condition  signal_count  \\\n",
       "0               1            0.0     control   mindful             1   \n",
       "1               2            0.0      active   mindful             2   \n",
       "2               3            0.0      active   mindful             3   \n",
       "3               4            0.0      active   mindful             4   \n",
       "4               5            0.0      active   mindful             5   \n",
       "...           ...            ...         ...       ...           ...   \n",
       "18196       12149            NaN      active   mindful            52   \n",
       "18197       12150            0.0      active   mindful            53   \n",
       "18198       12151            0.0      active   mindful            54   \n",
       "18199       12152            NaN      active   mindful            55   \n",
       "18200       12153            NaN      active   mindful            56   \n",
       "\n",
       "       alc_responses social_weekend group        id  \n",
       "0                 53        Weekend   g2p   muri012  \n",
       "1                 53        Weekend   g2p   muri012  \n",
       "2                 53        Weekend   g2p   muri012  \n",
       "3                 53           Week   g2p   muri012  \n",
       "4                 53           Week   g2p   muri012  \n",
       "...              ...            ...   ...       ...  \n",
       "18196             49        Weekend   g4c  muric553  \n",
       "18197             49        Weekend   g4c  muric553  \n",
       "18198             49        Weekend   g4c  muric553  \n",
       "18199             49        Weekend   g4c  muric553  \n",
       "18200             49        Weekend   g4c  muric553  \n",
       "\n",
       "[18201 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.concat([data_study1, data_study2], ignore_index=True)\n",
    "combined_data.dropna()\n",
    "combined_data = combined_data.drop_duplicates(subset=[\n",
    "    'drinks_number', 'active_week', 'condition', \n",
    "    'signal_count', 'alc_responses', 'social_weekend', \n",
    "    'group', 'id'\n",
    "])\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active_week",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "drinks_number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "drinking_occasions",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "03ae198f-961d-4d17-b5b2-cb13c1377c06",
       "rows": [
        [
         "0",
         "muri011",
         "control",
         "control",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "muri012",
         "active",
         "mindful",
         "g2p",
         "1.0",
         "0.5"
        ],
        [
         "2",
         "muri012",
         "control",
         "mindful",
         "g2p",
         "2.0",
         "0.5"
        ],
        [
         "3",
         "muri015",
         "active",
         "perspective",
         "g2p",
         "9.0",
         "1.0"
        ],
        [
         "4",
         "muri015",
         "control",
         "perspective",
         "g2p",
         "19.0",
         "1.5"
        ],
        [
         "5",
         "muri016 ",
         "active",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "muri016 ",
         "control",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "muri017",
         "active",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "muri017",
         "control",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "muri018",
         "active",
         "perspective",
         "g2p",
         "18.0",
         "2.5"
        ],
        [
         "10",
         "muri018",
         "control",
         "perspective",
         "g2p",
         "26.0",
         "3.0"
        ],
        [
         "11",
         "muri023",
         "active",
         "perspective",
         "g2p",
         "1.0",
         "0.5"
        ],
        [
         "12",
         "muri023",
         "control",
         "perspective",
         "g2p",
         "6.0",
         "2.0"
        ],
        [
         "13",
         "muri024",
         "control",
         "control",
         "g2p",
         "3.0",
         "1.0"
        ],
        [
         "14",
         "muri028",
         "active",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "muri028",
         "control",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "muri034",
         "active",
         "perspective",
         "g2p",
         "5.0",
         "2.0"
        ],
        [
         "17",
         "muri034",
         "control",
         "perspective",
         "g2p",
         "15.0",
         "3.5"
        ],
        [
         "18",
         "muri041",
         "active",
         "mindful",
         "g2p",
         "2.0",
         "1.0"
        ],
        [
         "19",
         "muri041",
         "control",
         "mindful",
         "g2p",
         "15.0",
         "1.0"
        ],
        [
         "20",
         "muri042",
         "active",
         "mindful",
         "g2p",
         "1.0",
         "0.5"
        ],
        [
         "21",
         "muri042",
         "control",
         "mindful",
         "g2p",
         "9.0",
         "2.0"
        ],
        [
         "22",
         "muri043",
         "active",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "muri043",
         "control",
         "perspective",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "muri046",
         "control",
         "control",
         "g2p",
         "14.0",
         "3.5"
        ],
        [
         "25",
         "muri047",
         "control",
         "control",
         "g2p",
         "3.0",
         "1.0"
        ],
        [
         "26",
         "muri053",
         "control",
         "control",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "27",
         "muri055",
         "control",
         "control",
         "g2p",
         "11.0",
         "5.5"
        ],
        [
         "28",
         "muri061",
         "control",
         "control",
         "g2p",
         "31.0",
         "3.5"
        ],
        [
         "29",
         "muri062",
         "control",
         "control",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "30",
         "muri063",
         "active",
         "mindful",
         "g2p",
         "3.0",
         "1.0"
        ],
        [
         "31",
         "muri063",
         "control",
         "mindful",
         "g2p",
         "14.0",
         "2.5"
        ],
        [
         "32",
         "muri067",
         "control",
         "control",
         "g2p",
         "75.0",
         "6.0"
        ],
        [
         "33",
         "muri071",
         "control",
         "control",
         "g2p",
         "31.0",
         "5.0"
        ],
        [
         "34",
         "muri077",
         "active",
         "perspective",
         "g2p",
         "10.0",
         "2.5"
        ],
        [
         "35",
         "muri077",
         "control",
         "perspective",
         "g2p",
         "14.0",
         "4.0"
        ],
        [
         "36",
         "muri078",
         "active",
         "mindful",
         "g2p",
         "23.0",
         "3.5"
        ],
        [
         "37",
         "muri078",
         "control",
         "mindful",
         "g2p",
         "34.0",
         "5.0"
        ],
        [
         "38",
         "muri080",
         "active",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "muri080",
         "control",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "muri082",
         "active",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "41",
         "muri082",
         "control",
         "mindful",
         "g2p",
         "0.0",
         "0.0"
        ],
        [
         "42",
         "muri085",
         "active",
         "mindful",
         "g3p",
         "1.0",
         "0.5"
        ],
        [
         "43",
         "muri085",
         "control",
         "mindful",
         "g3p",
         "4.0",
         "2.0"
        ],
        [
         "44",
         "muri086",
         "active",
         "mindful",
         "g3p",
         "2.0",
         "0.5"
        ],
        [
         "45",
         "muri086",
         "control",
         "mindful",
         "g3p",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "muri087",
         "active",
         "mindful",
         "g3p",
         "13.0",
         "2.5"
        ],
        [
         "47",
         "muri087",
         "control",
         "mindful",
         "g3p",
         "6.0",
         "1.0"
        ],
        [
         "48",
         "muri088",
         "active",
         "mindful",
         "g3p",
         "3.0",
         "1.5"
        ],
        [
         "49",
         "muri088",
         "control",
         "mindful",
         "g3p",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 539
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>active_week</th>\n",
       "      <th>condition</th>\n",
       "      <th>group</th>\n",
       "      <th>drinks_number</th>\n",
       "      <th>drinking_occasions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muri011</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>g2p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muri012</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>g2p</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muri012</td>\n",
       "      <td>control</td>\n",
       "      <td>mindful</td>\n",
       "      <td>g2p</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muri015</td>\n",
       "      <td>active</td>\n",
       "      <td>perspective</td>\n",
       "      <td>g2p</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muri015</td>\n",
       "      <td>control</td>\n",
       "      <td>perspective</td>\n",
       "      <td>g2p</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>muric539</td>\n",
       "      <td>active</td>\n",
       "      <td>perspective</td>\n",
       "      <td>g2c</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>muric539</td>\n",
       "      <td>control</td>\n",
       "      <td>perspective</td>\n",
       "      <td>g2c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>muric551</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>g4c</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>muric553</td>\n",
       "      <td>active</td>\n",
       "      <td>mindful</td>\n",
       "      <td>g4c</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>muric553</td>\n",
       "      <td>control</td>\n",
       "      <td>mindful</td>\n",
       "      <td>g4c</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id active_week    condition group  drinks_number  \\\n",
       "0     muri011     control      control   g2p            0.0   \n",
       "1     muri012      active      mindful   g2p            1.0   \n",
       "2     muri012     control      mindful   g2p            2.0   \n",
       "3     muri015      active  perspective   g2p            9.0   \n",
       "4     muri015     control  perspective   g2p           19.0   \n",
       "..        ...         ...          ...   ...            ...   \n",
       "534  muric539      active  perspective   g2c            4.0   \n",
       "535  muric539     control  perspective   g2c            3.0   \n",
       "536  muric551     control      control   g4c           14.0   \n",
       "537  muric553      active      mindful   g4c           34.0   \n",
       "538  muric553     control      mindful   g4c           44.0   \n",
       "\n",
       "     drinking_occasions  \n",
       "0                   0.0  \n",
       "1                   0.5  \n",
       "2                   0.5  \n",
       "3                   1.0  \n",
       "4                   1.5  \n",
       "..                  ...  \n",
       "534                 1.0  \n",
       "535                 1.0  \n",
       "536                 3.0  \n",
       "537                 3.0  \n",
       "538                 6.5  \n",
       "\n",
       "[539 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df = combined_data.dropna(subset=['id', 'group', 'condition', 'active_week', 'social_weekend'])\n",
    "\n",
    "# sum up num drinks, lambda func for assigning drinking occasions\n",
    "aggregated_df = aggregated_df.groupby(['id', 'active_week', 'condition', 'group'], as_index=False).agg({\n",
    "    'drinks_number': ['sum', lambda x: (x > 0).sum()]\n",
    "})\n",
    "\n",
    "aggregated_df.columns = ['id', 'active_week', 'condition', 'group', 'drinks_number', 'drinking_occasions']\n",
    "\n",
    "# assuming 2 weeks active vs 2 weeks control: div2 to get avg drinks/drinking occasions in active/control weeks\n",
    "aggregated_df['drinking_occasions'] = aggregated_df['drinking_occasions'] / 2\n",
    "\n",
    "duplicates_count = aggregated_df.duplicated(subset=['id', 'active_week', 'condition', 'group']).sum()\n",
    "aggregated_df = aggregated_df.drop_duplicates(subset=['id', 'active_week', 'condition', 'group'], keep=False)\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "drinks_number",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "active_week",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "signal_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alc_responses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "social_weekend",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b790e426-f966-4c84-b86a-5ef53dd46c5f",
       "rows": [
        [
         "224",
         "225",
         "0.0",
         "control",
         "control",
         "1",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "225",
         "226",
         "5.0",
         "control",
         "control",
         "2",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "226",
         "227",
         "0.0",
         "control",
         "control",
         "3",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "227",
         "228",
         "0.0",
         "control",
         "control",
         "4",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "228",
         "229",
         "0.0",
         "control",
         "control",
         "5",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "229",
         "230",
         "0.0",
         "control",
         "control",
         "6",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "230",
         "231",
         "0.0",
         "control",
         "control",
         "7",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "231",
         "232",
         "0.0",
         "control",
         "control",
         "8",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "232",
         "233",
         "0.0",
         "control",
         "control",
         "9",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "233",
         "234",
         "0.0",
         "control",
         "control",
         "10",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "234",
         "235",
         "0.0",
         "control",
         "control",
         "11",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "235",
         "236",
         "0.0",
         "control",
         "control",
         "12",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "236",
         "237",
         "0.0",
         "control",
         "control",
         "13",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "237",
         "238",
         "0.0",
         "control",
         "control",
         "14",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "238",
         "239",
         "0.0",
         "control",
         "control",
         "15",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "239",
         "240",
         "0.0",
         "control",
         "control",
         "16",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "240",
         "241",
         "3.0",
         "control",
         "control",
         "17",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "241",
         "242",
         "0.0",
         "control",
         "control",
         "18",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "242",
         "243",
         "0.0",
         "control",
         "control",
         "19",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "243",
         "244",
         "0.0",
         "control",
         "control",
         "20",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "244",
         "245",
         "0.0",
         "control",
         "control",
         "21",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "245",
         "246",
         "0.0",
         "control",
         "control",
         "22",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "246",
         "247",
         "0.0",
         "control",
         "control",
         "23",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "247",
         "248",
         "0.0",
         "control",
         "control",
         "24",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "248",
         "249",
         "0.0",
         "control",
         "control",
         "25",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "249",
         "250",
         "0.0",
         "control",
         "control",
         "26",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "250",
         "251",
         "0.0",
         "control",
         "control",
         "27",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "251",
         "252",
         "0.0",
         "control",
         "control",
         "28",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "252",
         "253",
         "0.0",
         "control",
         "control",
         "29",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "253",
         "254",
         "0.0",
         "control",
         "control",
         "30",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "254",
         "255",
         "0.0",
         "control",
         "control",
         "31",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "255",
         "256",
         "0.0",
         "control",
         "control",
         "32",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "256",
         "257",
         "0.0",
         "control",
         "control",
         "33",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "257",
         "258",
         null,
         "control",
         "control",
         "34",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "258",
         "259",
         "0.0",
         "control",
         "control",
         "35",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "259",
         "260",
         "0.0",
         "control",
         "control",
         "36",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "260",
         "261",
         "0.0",
         "control",
         "control",
         "37",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "261",
         "262",
         "0.0",
         "control",
         "control",
         "38",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "262",
         "263",
         "0.0",
         "control",
         "control",
         "39",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "263",
         "264",
         "0.0",
         "control",
         "control",
         "40",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "264",
         "265",
         "5.0",
         "control",
         "control",
         "41",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "265",
         "266",
         "0.0",
         "control",
         "control",
         "42",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "266",
         "267",
         "3.0",
         "control",
         "control",
         "43",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "267",
         "268",
         "6.0",
         "control",
         "control",
         "44",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "268",
         "269",
         "0.0",
         "control",
         "control",
         "45",
         "55",
         "Weekend",
         "g2p",
         "muri061"
        ],
        [
         "269",
         "270",
         "0.0",
         "control",
         "control",
         "46",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "270",
         "271",
         "0.0",
         "control",
         "control",
         "47",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "271",
         "272",
         "0.0",
         "control",
         "control",
         "48",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "272",
         "273",
         "0.0",
         "control",
         "control",
         "49",
         "55",
         "Week",
         "g2p",
         "muri061"
        ],
        [
         "273",
         "274",
         "0.0",
         "control",
         "control",
         "50",
         "55",
         "Week",
         "g2p",
         "muri061"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5870
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drinks_number</th>\n",
       "      <th>active_week</th>\n",
       "      <th>condition</th>\n",
       "      <th>signal_count</th>\n",
       "      <th>alc_responses</th>\n",
       "      <th>social_weekend</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>226</td>\n",
       "      <td>5.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>Week</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>Week</td>\n",
       "      <td>g2p</td>\n",
       "      <td>muri061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18140</th>\n",
       "      <td>12093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>12094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18142</th>\n",
       "      <td>12095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18143</th>\n",
       "      <td>12096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18144</th>\n",
       "      <td>12097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>Week</td>\n",
       "      <td>g4c</td>\n",
       "      <td>muric551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5870 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  drinks_number active_week condition  signal_count  \\\n",
       "224           225            0.0     control   control             1   \n",
       "225           226            5.0     control   control             2   \n",
       "226           227            0.0     control   control             3   \n",
       "227           228            0.0     control   control             4   \n",
       "228           229            0.0     control   control             5   \n",
       "...           ...            ...         ...       ...           ...   \n",
       "18140       12093            0.0     control   control            52   \n",
       "18141       12094            0.0     control   control            53   \n",
       "18142       12095            0.0     control   control            54   \n",
       "18143       12096            0.0     control   control            55   \n",
       "18144       12097            0.0     control   control            56   \n",
       "\n",
       "       alc_responses social_weekend group        id  \n",
       "224               55        Weekend   g2p   muri061  \n",
       "225               55        Weekend   g2p   muri061  \n",
       "226               55        Weekend   g2p   muri061  \n",
       "227               55           Week   g2p   muri061  \n",
       "228               55           Week   g2p   muri061  \n",
       "...              ...            ...   ...       ...  \n",
       "18140             53           Week   g4c  muric551  \n",
       "18141             53           Week   g4c  muric551  \n",
       "18142             53           Week   g4c  muric551  \n",
       "18143             53           Week   g4c  muric551  \n",
       "18144             53           Week   g4c  muric551  \n",
       "\n",
       "[5870 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Filter for control condition before grouping\n",
    "control_only = combined_data.dropna(subset=['id', 'group', 'condition', 'active_week', 'social_weekend'])\n",
    "control_only = control_only[control_only['condition'] == 'control']\n",
    "\n",
    "# Step 2: Make a copy\n",
    "control_only\n",
    "\n",
    "# Step 3: Aggregate control data\n",
    "# aggregated_control = control_only_copy.groupby(['id', 'active_week', 'condition', 'group'], as_index=False).agg({\n",
    "#     'drinks_number': ['sum', lambda x: (x > 0).sum()]\n",
    "# })\n",
    "\n",
    "# # Step 4: Rename columns\n",
    "# aggregated_control.columns = ['id', 'active_week', 'condition', 'group', 'drinks_number', 'drinking_occasions']\n",
    "\n",
    "# # Step 5: Divide by 2 if needed (e.g. assuming 2 active/control weeks per person)\n",
    "# aggregated_control['drinking_occasions'] = aggregated_control['drinking_occasions'] / 2\n",
    "\n",
    "# # Optional: Check for duplicates\n",
    "# duplicates_control = aggregated_control.duplicated(subset=['id', 'active_week', 'condition', 'group']).sum()\n",
    "# aggregated_control = aggregated_control.drop_duplicates(subset=['id', 'active_week', 'condition', 'group'], keep=False)\n",
    "\n",
    "# aggregated_control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_only['week'] = ((control_only['signal_count'] - 1) // 14 + 1).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure drinks_number is numeric\n",
    "control_only['drinks_number'] = pd.to_numeric(control_only['drinks_number'], errors='coerce')\n",
    "\n",
    "# Create the drinking_occasions summary\n",
    "drinking_summary = (\n",
    "    control_only\n",
    "    .groupby(['id', 'week'])['drinks_number']\n",
    "    .apply(lambda x: (x > 0).sum())\n",
    "    .reset_index(name='drinking_occasions')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drinking_summary.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinking_summary.to_csv(os.path.join('../../SHINE/final_buckets', 'weekly_drinking_summary_controlgroup.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates dropped: 0\n",
      "-----------------------\n",
      "Num participants study1: 108\n",
      "Num participants study2: 218\n",
      "-----------------------\n",
      "N for study2 && 'mindful': 37\n",
      "N for study2 && 'perspective': 34\n",
      "N for study2 && 'control': 37\n",
      "-----------------------\n",
      "N for study2 && 'mindful': 75\n",
      "N for study2 && 'perspective': 72\n",
      "N for study2 && 'control': 71\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "\n",
    "print(f\"Number of duplicates dropped: {duplicates_count}\")\n",
    "aggregated_df.head(25)\n",
    "\n",
    "print(\"-----------------------\")\n",
    "\n",
    "print(f\"Num participants study1: {data_study1['id'].nunique()}\")\n",
    "print(f\"Num participants study2: {data_study2['id'].nunique()}\")\n",
    "\n",
    "print(\"-----------------------\")\n",
    "\n",
    "for condition in ['mindful', 'perspective', 'control']:\n",
    "    num_unique_ids = data_study1[data_study1['condition'] == condition]['id'].nunique()\n",
    "    print(f\"N for study2 && '{condition}': {num_unique_ids}\")\n",
    "\n",
    "print(\"-----------------------\")\n",
    "\n",
    "for condition in ['mindful', 'perspective', 'control']:\n",
    "    num_unique_ids = data_study2[data_study2['condition'] == condition]['id'].nunique()\n",
    "    print(f\"N for study2 && '{condition}': {num_unique_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = True # set to true to run plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "control",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6fab6812-dbfe-4eb7-9390-7ad423d59974",
       "rows": [
        [
         "0",
         "muri012",
         "g2p",
         "mindful",
         "0.5",
         "0.5"
        ],
        [
         "1",
         "muri015",
         "g2p",
         "perspective",
         "1.0",
         "1.5"
        ],
        [
         "2",
         "muri016 ",
         "g2p",
         "perspective",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "muri017",
         "g2p",
         "perspective",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "muri018",
         "g2p",
         "perspective",
         "2.5",
         "3.0"
        ],
        [
         "5",
         "muri023",
         "g2p",
         "perspective",
         "0.5",
         "2.0"
        ],
        [
         "6",
         "muri028",
         "g2p",
         "mindful",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "muri034",
         "g2p",
         "perspective",
         "2.0",
         "3.5"
        ],
        [
         "8",
         "muri041",
         "g2p",
         "mindful",
         "1.0",
         "1.0"
        ],
        [
         "9",
         "muri042",
         "g2p",
         "mindful",
         "0.5",
         "2.0"
        ],
        [
         "10",
         "muri043",
         "g2p",
         "perspective",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "muri063",
         "g2p",
         "mindful",
         "1.0",
         "2.5"
        ],
        [
         "12",
         "muri077",
         "g2p",
         "perspective",
         "2.5",
         "4.0"
        ],
        [
         "13",
         "muri078",
         "g2p",
         "mindful",
         "3.5",
         "5.0"
        ],
        [
         "14",
         "muri080",
         "g2p",
         "mindful",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "muri082",
         "g2p",
         "mindful",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "muri085",
         "g3p",
         "mindful",
         "0.5",
         "2.0"
        ],
        [
         "17",
         "muri086",
         "g3p",
         "mindful",
         "0.5",
         "0.0"
        ],
        [
         "18",
         "muri087",
         "g3p",
         "mindful",
         "2.5",
         "1.0"
        ],
        [
         "19",
         "muri088",
         "g3p",
         "mindful",
         "1.5",
         "0.0"
        ],
        [
         "20",
         "muri091",
         "g3p",
         "perspective",
         "0.5",
         "0.0"
        ],
        [
         "21",
         "muri092",
         "g3p",
         "perspective",
         "5.0",
         "5.5"
        ],
        [
         "22",
         "muri096",
         "g3p",
         "perspective",
         "2.0",
         "1.0"
        ],
        [
         "23",
         "muri098",
         "g3p",
         "mindful",
         "2.0",
         "1.5"
        ],
        [
         "24",
         "muri100",
         "g3p",
         "perspective",
         "1.0",
         "1.5"
        ],
        [
         "25",
         "muri101",
         "g3p",
         "mindful",
         "1.0",
         "3.0"
        ],
        [
         "26",
         "muri101 ",
         "g3p",
         "mindful",
         "0.0",
         "2.5"
        ],
        [
         "27",
         "muri104",
         "g3p",
         "perspective",
         "0.5",
         "1.0"
        ],
        [
         "28",
         "muri117",
         "g3p",
         "mindful",
         "2.0",
         "1.0"
        ],
        [
         "29",
         "muri146",
         "g5p",
         "perspective",
         "1.0",
         "1.0"
        ],
        [
         "30",
         "muri147",
         "g5p",
         "perspective",
         "0.5",
         "0.5"
        ],
        [
         "31",
         "muri151",
         "g5p",
         "perspective",
         "1.0",
         "2.0"
        ],
        [
         "32",
         "muri163",
         "g5p",
         "mindful",
         "1.0",
         "3.0"
        ],
        [
         "33",
         "muri173",
         "g5p",
         "perspective",
         "0.5",
         "0.5"
        ],
        [
         "34",
         "muri186",
         "g5p",
         "mindful",
         "1.0",
         "1.5"
        ],
        [
         "35",
         "muri190",
         "g5p",
         "mindful",
         "0.5",
         "1.0"
        ],
        [
         "36",
         "muri196",
         "g5p",
         "perspective",
         "4.5",
         "5.0"
        ],
        [
         "37",
         "muri201",
         "g5p",
         "perspective",
         "3.5",
         "4.0"
        ],
        [
         "38",
         "muri213",
         "g6p",
         "mindful",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "muri223",
         "g6p",
         "perspective",
         "0.0",
         "0.5"
        ],
        [
         "40",
         "muri230",
         "g7p",
         "mindful",
         "2.0",
         "1.0"
        ],
        [
         "41",
         "muri240",
         "g7p",
         "perspective",
         "3.0",
         "4.0"
        ],
        [
         "42",
         "muri245",
         "g7p",
         "mindful",
         "0.0",
         "0.5"
        ],
        [
         "43",
         "muri248",
         "g7p",
         "mindful",
         "2.0",
         "1.5"
        ],
        [
         "44",
         "muri249",
         "g7p",
         "perspective",
         "1.5",
         "1.5"
        ],
        [
         "45",
         "muri275",
         "g8p",
         "mindful",
         "5.0",
         "4.5"
        ],
        [
         "46",
         "muri308",
         "g9p",
         "mindful",
         "0.0",
         "0.0"
        ],
        [
         "47",
         "muri318",
         "g9p",
         "perspective",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "muri321",
         "g9p",
         "mindful",
         "7.0",
         "3.5"
        ],
        [
         "49",
         "muri326",
         "g9p",
         "perspective",
         "4.5",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>active_week</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>condition</th>\n",
       "      <th>active</th>\n",
       "      <th>control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muri012</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muri015</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muri016</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muri017</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muri018</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muri023</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>muri028</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>muri034</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>muri041</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>muri042</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>muri043</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>muri063</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>muri077</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>muri078</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>muri080</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>muri082</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>muri085</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>muri086</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>muri087</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>muri088</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>muri091</td>\n",
       "      <td>g3p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>muri092</td>\n",
       "      <td>g3p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>muri096</td>\n",
       "      <td>g3p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>muri098</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>muri100</td>\n",
       "      <td>g3p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>muri101</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>muri101</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>muri104</td>\n",
       "      <td>g3p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>muri117</td>\n",
       "      <td>g3p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>muri146</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>muri147</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>muri151</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>muri163</td>\n",
       "      <td>g5p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>muri173</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>muri186</td>\n",
       "      <td>g5p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>muri190</td>\n",
       "      <td>g5p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>muri196</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>muri201</td>\n",
       "      <td>g5p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>muri213</td>\n",
       "      <td>g6p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>muri223</td>\n",
       "      <td>g6p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>muri230</td>\n",
       "      <td>g7p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>muri240</td>\n",
       "      <td>g7p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>muri245</td>\n",
       "      <td>g7p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>muri248</td>\n",
       "      <td>g7p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>muri249</td>\n",
       "      <td>g7p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>muri275</td>\n",
       "      <td>g8p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>muri308</td>\n",
       "      <td>g9p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>muri318</td>\n",
       "      <td>g9p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>muri321</td>\n",
       "      <td>g9p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>muri326</td>\n",
       "      <td>g9p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "active_week        id group    condition  active  control\n",
       "0             muri012   g2p      mindful     0.5      0.5\n",
       "1             muri015   g2p  perspective     1.0      1.5\n",
       "2            muri016    g2p  perspective     0.0      0.0\n",
       "3             muri017   g2p  perspective     0.0      0.0\n",
       "4             muri018   g2p  perspective     2.5      3.0\n",
       "5             muri023   g2p  perspective     0.5      2.0\n",
       "6             muri028   g2p      mindful     0.0      0.0\n",
       "7             muri034   g2p  perspective     2.0      3.5\n",
       "8             muri041   g2p      mindful     1.0      1.0\n",
       "9             muri042   g2p      mindful     0.5      2.0\n",
       "10            muri043   g2p  perspective     0.0      0.0\n",
       "11            muri063   g2p      mindful     1.0      2.5\n",
       "12            muri077   g2p  perspective     2.5      4.0\n",
       "13            muri078   g2p      mindful     3.5      5.0\n",
       "14            muri080   g2p      mindful     0.0      0.0\n",
       "15            muri082   g2p      mindful     0.0      0.0\n",
       "16            muri085   g3p      mindful     0.5      2.0\n",
       "17            muri086   g3p      mindful     0.5      0.0\n",
       "18            muri087   g3p      mindful     2.5      1.0\n",
       "19            muri088   g3p      mindful     1.5      0.0\n",
       "20            muri091   g3p  perspective     0.5      0.0\n",
       "21            muri092   g3p  perspective     5.0      5.5\n",
       "22            muri096   g3p  perspective     2.0      1.0\n",
       "23            muri098   g3p      mindful     2.0      1.5\n",
       "24            muri100   g3p  perspective     1.0      1.5\n",
       "25            muri101   g3p      mindful     1.0      3.0\n",
       "26           muri101    g3p      mindful     0.0      2.5\n",
       "27            muri104   g3p  perspective     0.5      1.0\n",
       "28            muri117   g3p      mindful     2.0      1.0\n",
       "29            muri146   g5p  perspective     1.0      1.0\n",
       "30            muri147   g5p  perspective     0.5      0.5\n",
       "31            muri151   g5p  perspective     1.0      2.0\n",
       "32            muri163   g5p      mindful     1.0      3.0\n",
       "33            muri173   g5p  perspective     0.5      0.5\n",
       "34            muri186   g5p      mindful     1.0      1.5\n",
       "35            muri190   g5p      mindful     0.5      1.0\n",
       "36            muri196   g5p  perspective     4.5      5.0\n",
       "37            muri201   g5p  perspective     3.5      4.0\n",
       "38            muri213   g6p      mindful     0.0      0.0\n",
       "39            muri223   g6p  perspective     0.0      0.5\n",
       "40            muri230   g7p      mindful     2.0      1.0\n",
       "41            muri240   g7p  perspective     3.0      4.0\n",
       "42            muri245   g7p      mindful     0.0      0.5\n",
       "43            muri248   g7p      mindful     2.0      1.5\n",
       "44            muri249   g7p  perspective     1.5      1.5\n",
       "45            muri275   g8p      mindful     5.0      4.5\n",
       "46            muri308   g9p      mindful     0.0      0.0\n",
       "47            muri318   g9p  perspective     0.0      0.0\n",
       "48            muri321   g9p      mindful     7.0      3.5\n",
       "49            muri326   g9p  perspective     4.5      4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for IDs that belong to any condition\n",
    "filtered_df = aggregated_df[aggregated_df['condition'].isin(['mindful', 'perspective'])]\n",
    "\n",
    "# Pivot for scatter plot preparation for drinking_occasions\n",
    "pivot_df_occasions = filtered_df.pivot(index=['id', 'group', 'condition'], columns='active_week', values='drinking_occasions').reset_index()\n",
    "\n",
    "\n",
    "if plot:\n",
    "    # Plot scatter for drinking_occasions\n",
    "    plt.figure()\n",
    "    for condition in ['mindful', 'perspective']:\n",
    "        condition_df = pivot_df_occasions[pivot_df_occasions['condition'] == condition]\n",
    "        plt.scatter(condition_df['control'], condition_df['active'], label=condition)\n",
    "\n",
    "    plt.xlabel(\"Control Drinking Occasions\")\n",
    "    plt.ylabel(\"Active Drinking Occasions\")\n",
    "    plt.title(\"Control vs Active for Mindful and Perspective (Drinking Occasions)\")\n",
    "    plt.legend(title=\"Condition\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "pivot_df_occasions.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot_df_occasions['difference_drinks_occasions'] = pivot_df_occasions['active'] - pivot_df_occasions['control']\n",
    "\n",
    "pivot_df_occasions['metric'] = 'Drinking Occasions'\n",
    "\n",
    "if plot:\n",
    "    # Plot for drinking occasions\n",
    "    sns.boxplot(\n",
    "        data=pivot_df_occasions,\n",
    "        y='difference_drinks_occasions',\n",
    "        x='metric',\n",
    "        showcaps=True,\n",
    "        boxprops={'facecolor': 'lightblue'},  # Add color to the box\n",
    "        whiskerprops={'linewidth': 1.5},\n",
    "        palette='muted'  # Use a colorful palette\n",
    "    )\n",
    "    sns.swarmplot(\n",
    "        data=pivot_df_occasions,\n",
    "        y='difference_drinks_occasions',\n",
    "        x='metric',\n",
    "        palette='bright',  # Use a colorful palette for swarm points\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.title(\"Difference in Drinking Occasions\", fontsize=14)\n",
    "    plt.ylabel(\"Difference (Active - Control)\", fontsize=12)\n",
    "    plt.xlabel(\"\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate responsiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "control",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "difference_drinks_occasions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "responsive",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e0077157-08fc-47c5-993b-c124fe31c119",
       "rows": [
        [
         "0",
         "muri012",
         "g2p",
         "mindful",
         "0.5",
         "0.5",
         "0.0",
         "Drinking Occasions",
         "0"
        ],
        [
         "1",
         "muri015",
         "g2p",
         "perspective",
         "1.0",
         "1.5",
         "-0.5",
         "Drinking Occasions",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>active_week</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>condition</th>\n",
       "      <th>active</th>\n",
       "      <th>control</th>\n",
       "      <th>difference_drinks_occasions</th>\n",
       "      <th>metric</th>\n",
       "      <th>responsive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muri012</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Drinking Occasions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muri015</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>Drinking Occasions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "active_week       id group    condition  active  control  \\\n",
       "0            muri012   g2p      mindful     0.5      0.5   \n",
       "1            muri015   g2p  perspective     1.0      1.5   \n",
       "\n",
       "active_week  difference_drinks_occasions              metric  responsive  \n",
       "0                                    0.0  Drinking Occasions           0  \n",
       "1                                   -0.5  Drinking Occasions           0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pre-defined threshold to define who is and is not responsive\n",
    "pivot_df_occasions['responsive'] = (pivot_df_occasions['difference_drinks_occasions'] < def_response_drink_occasions).astype(int)\n",
    "\n",
    "pivot_df_occasions.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 218\n",
      "Responsive (drinking occasions): 14\n"
     ]
    }
   ],
   "source": [
    "responsive_ids_occasions = pivot_df_occasions[pivot_df_occasions['responsive'] == 1]['id'].nunique()\n",
    "\n",
    "print(f\"Total sample size: {pivot_df_occasions['id'].nunique()}\")\n",
    "print(f'Responsive (drinking occasions): {responsive_ids_occasions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsiveness_df = pivot_df_occasions\n",
    "responsiveness_df.drop_duplicates(subset=['id'])\n",
    "len(responsiveness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "responsiveness_df.drop(columns=['metric'], inplace=True)\n",
    "responsiveness_df.to_csv(os.path.join('../../SHINE/final_buckets', 'responsive_users_standard.csv'), index=False)\n",
    "\n",
    "# Get unique participant IDs for each study\n",
    "ids_study1 = set(data_study1['id'].unique())\n",
    "ids_study2 = set(data_study2['id'].unique())\n",
    "\n",
    "# Subset the main DataFrame\n",
    "df_study1 = responsiveness_df[responsiveness_df['id'].isin(ids_study1)]\n",
    "df_study2 = responsiveness_df[responsiveness_df['id'].isin(ids_study2)]\n",
    "\n",
    "print(len(df_study1))\n",
    "print(len(df_study2))\n",
    "\n",
    "# Save the files\n",
    "df_study1.to_csv(os.path.join('../../SHINE/final_buckets', f'responsiveness_study1_{def_response_drink_occasions}.csv'), index=False)\n",
    "df_study2.to_csv(os.path.join('../../SHINE/final_buckets', 'responsiveness_study2.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Baseline Data (Buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    'Unnamed: 0', 'pID', 'X.1', 'X', 'Alcohol_Size_None_sum',\n",
    "       'Alcohol_Size_One_sum', 'Alcohol_Size_Small_sum',\n",
    "       'Alcohol_Size_Large_sum''Condition', 'SHINEID', \n",
    "       'Alc_Encounter_sum', \n",
    "       'Craving_Alc_mean', \n",
    "       'Converse_Alc_sum', \n",
    "       'Alc_Converse_Valence_mean', \n",
    "       'NegativeMood_mean'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_VARS = [\n",
    "    'id', 'group', 'condition', 'active',\n",
    "    'control', 'difference_drinks_occasions',\n",
    "    'metric', 'responsive'] \n",
    "\n",
    "# common vars and vars including alcohol encounter data need to be excluded from training data in all cases\n",
    "EXCLUDE_VARS = COMMON_VARS + exclude_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "active",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "control",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "difference_drinks_occasions",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "responsive",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a25b60d5-7376-4072-9eb7-003bd694cb41",
       "rows": [
        [
         "0",
         "muri012",
         "g2p",
         "mindful",
         "0.5",
         "0.5",
         "0.0",
         "0"
        ],
        [
         "1",
         "muri015",
         "g2p",
         "perspective",
         "1.0",
         "1.5",
         "-0.5",
         "0"
        ],
        [
         "2",
         "muri016 ",
         "g2p",
         "perspective",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "3",
         "muri017",
         "g2p",
         "perspective",
         "0.0",
         "0.0",
         "0.0",
         "0"
        ],
        [
         "4",
         "muri018",
         "g2p",
         "perspective",
         "2.5",
         "3.0",
         "-0.5",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>active_week</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>condition</th>\n",
       "      <th>active</th>\n",
       "      <th>control</th>\n",
       "      <th>difference_drinks_occasions</th>\n",
       "      <th>responsive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muri012</td>\n",
       "      <td>g2p</td>\n",
       "      <td>mindful</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muri015</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muri016</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muri017</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muri018</td>\n",
       "      <td>g2p</td>\n",
       "      <td>perspective</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "active_week        id group    condition  active  control  \\\n",
       "0             muri012   g2p      mindful     0.5      0.5   \n",
       "1             muri015   g2p  perspective     1.0      1.5   \n",
       "2            muri016    g2p  perspective     0.0      0.0   \n",
       "3             muri017   g2p  perspective     0.0      0.0   \n",
       "4             muri018   g2p  perspective     2.5      3.0   \n",
       "\n",
       "active_week  difference_drinks_occasions  responsive  \n",
       "0                                    0.0           0  \n",
       "1                                   -0.5           0  \n",
       "2                                    0.0           0  \n",
       "3                                    0.0           0  \n",
       "4                                   -0.5           0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responsiveness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'ROI_alc_react_v_rest_neurosynth_cogcontrol',\n",
      "       'ROI_alc_react_v_rest_neurosynth_craving',\n",
      "       'ROI_alc_react_v_rest_neurosynth_emoreg',\n",
      "       'ROI_alc_react_v_rest_neurosynth_reward',\n",
      "       'segregation_resting_state_total', 'reward', 'mentalizing',\n",
      "       'ROI_alc_react_v_rest_VS'],\n",
      "      dtype='object')\n",
      "Index(['id', 'group', 'condition', 'active', 'control',\n",
      "       'difference_drinks_occasions', 'responsive'],\n",
      "      dtype='object', name='active_week')\n"
     ]
    }
   ],
   "source": [
    "print(b4_brain.columns)\n",
    "print(responsiveness_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b1_alcohol_self.columns) + len(b2_group_subjective.columns) + len(b3_group_sociometric.columns) + len(b4_brain.columns) + len(b5_demographic.columns) + len(b6_psychometric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responsiveness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IDs: 69\n",
      "Responsive IDs: 6\n",
      "---------------\n",
      "Responsive & Mindful: 3\n",
      "Responsive & Perspective: 3\n"
     ]
    }
   ],
   "source": [
    "# b1_alcohol_self = pd.read_csv('../../SHINE/b1_alcohol_self.csv', index_col=0)\n",
    "# b2_group_subjective = pd.read_csv('../../SHINE/b2_group_subjective_new.csv', index_col=0)\n",
    "# b3_group_sociometric= pd.read_csv('../../SHINE/b3_group_sociometric.csv', index_col=0)\n",
    "# b4_brain= pd.read_csv('../../SHINE/b4_brain.csv', index_col=0)\n",
    "\n",
    "\n",
    "b1_alcohol_self_response = pd.merge(b1_alcohol_self, responsiveness_df, on='id', how='inner')\n",
    "b2_group_subjective_response = pd.merge(b2_group_subjective, responsiveness_df, on='id', how='inner')\n",
    "b2_group_subjective_response_old = pd.merge(b2_group_subjective_old, responsiveness_df, on='id', how='inner')\n",
    "b3_group_sociometric_response = pd.merge(b3_group_sociometric, responsiveness_df, on='id', how='inner')\n",
    "b4_brain_response = pd.merge(b4_brain, responsiveness_df, on='id', how='inner')\n",
    "b5_demographic_response = pd.merge(b5_demographic, responsiveness_df, on='id', how='inner')\n",
    "b6_psychometric_response = pd.merge(b6_psychometric, responsiveness_df, on='id', how='inner')\n",
    "b2_group_subjective_test = pd.merge(b2_group_subjective_test, responsiveness_df, on='id', how='inner')\n",
    "b2_group_subjective_test_study1 = pd.merge(b2_group_subjective_test_study1, responsiveness_df, on='id', how='inner')\n",
    "\n",
    "print(f'Total IDs: {len(b1_alcohol_self_response)}')\n",
    "print(f'Responsive IDs: {b1_alcohol_self_response[b1_alcohol_self_response[\"responsive\"] == 1][\"id\"].nunique()}')\n",
    "print(f'---------------')\n",
    "print(f'Responsive & Mindful: {b1_alcohol_self_response[(b1_alcohol_self_response[\"responsive\"] == 1) & (b1_alcohol_self_response[\"condition\"] == \"mindful\")][\"id\"].nunique()}')\n",
    "print(f'Responsive & Perspective: {b1_alcohol_self_response[(b1_alcohol_self_response[\"responsive\"] == 1) & (b1_alcohol_self_response[\"condition\"] == \"perspective\")][\"id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'avg_alcmost_freq', 'avg_alcmost', 'alc_norm_5_r', 'groupAtt_alc',\n",
       "       'groupAtt_binge', 'group', 'condition', 'active', 'control',\n",
       "       'difference_drinks_occasions', 'responsive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b2_group_subjective_test)\n",
    "b2_group_subjective_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'alc_self':\n",
      "id                                 0\n",
      "alc_binge_efficacy                 0\n",
      "alc_intent_binge                   0\n",
      "DMQ_drinking_coping_motive         0\n",
      "DMQ_drinking_enhancement_motive    0\n",
      "DMQ_drinking_social_motive         0\n",
      "DMQ_drinking_conformity_motive     0\n",
      "AUQ_drink_intent                   0\n",
      "AUQ_drink_frequency                0\n",
      "AUQ_drink_amount                   0\n",
      "alcohol_alc_att_1                  0\n",
      "alcohol_alc_att_2                  0\n",
      "DEQ_reduced_tension_exp            2\n",
      "DEQ_increased_confidence_exp       2\n",
      "DEQ_negative_consequences_exp      2\n",
      "DEQ_reduced_cognition_exp          2\n",
      "DEQ_increased_sexual_exp           2\n",
      "group                              0\n",
      "condition                          0\n",
      "active                             0\n",
      "control                            0\n",
      "difference_drinks_occasions        0\n",
      "responsive                         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in 'group_sub':\n",
      "id                             0\n",
      "avg_alcmost_freq               0\n",
      "avg_alcmost                    0\n",
      "alc_norm_5_r                   0\n",
      "groupAtt_alc                   0\n",
      "groupAtt_binge                 0\n",
      "group                          0\n",
      "condition                      0\n",
      "active                         0\n",
      "control                        0\n",
      "difference_drinks_occasions    0\n",
      "responsive                     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in 'group_socio':\n",
      "like_deg_in                    0\n",
      "alcLeast_deg_in                0\n",
      "alcMost_deg_in                 0\n",
      "closest_deg_in                 0\n",
      "influence_deg_in               0\n",
      "leaders_deg_in                 0\n",
      "goToBad_deg_in                 0\n",
      "goToGood_deg_in                0\n",
      "id                             0\n",
      "group                          0\n",
      "condition                      0\n",
      "active                         0\n",
      "control                        0\n",
      "difference_drinks_occasions    0\n",
      "responsive                     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in 'brain':\n",
      "id                                            0\n",
      "ROI_alc_react_v_rest_neurosynth_cogcontrol    0\n",
      "ROI_alc_react_v_rest_neurosynth_craving       0\n",
      "ROI_alc_react_v_rest_neurosynth_emoreg        0\n",
      "ROI_alc_react_v_rest_neurosynth_reward        0\n",
      "segregation_resting_state_total               0\n",
      "reward                                        0\n",
      "mentalizing                                   0\n",
      "ROI_alc_react_v_rest_VS                       0\n",
      "group                                         0\n",
      "condition                                     0\n",
      "active                                        0\n",
      "control                                       0\n",
      "difference_drinks_occasions                   0\n",
      "responsive                                    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in 'demo':\n",
      "id                             0\n",
      "college_year                   0\n",
      "age                            0\n",
      "gender_numeric                 0\n",
      "race_numeric                   0\n",
      "income_numeric                 5\n",
      "group                          0\n",
      "condition                      0\n",
      "active                         0\n",
      "control                        0\n",
      "difference_drinks_occasions    0\n",
      "responsive                     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in 'psych':\n",
      "id                             0\n",
      "STAI_mean                      0\n",
      "ACS_attentionshifting          0\n",
      "ACS_focus                      0\n",
      "ACS_mean                       0\n",
      "CESD_mean                      0\n",
      "MAAS_mean                      0\n",
      "RPI_mean                       0\n",
      "IAS_mean                       2\n",
      "PILS_mean                      0\n",
      "ULS.4_mean                     0\n",
      "DERS_clarity                   0\n",
      "DERS_goals                     0\n",
      "DERS_impulse                   0\n",
      "DERS_mean                      0\n",
      "DERS_nonacceptance             0\n",
      "DERS_strategies                0\n",
      "BIS_mean                       0\n",
      "BIS_attention_total            0\n",
      "BIS_motor_total                0\n",
      "BIS_nonplanning                0\n",
      "group                          0\n",
      "condition                      0\n",
      "active                         0\n",
      "control                        0\n",
      "difference_drinks_occasions    0\n",
      "responsive                     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "    'demo': b5_demographic_response,\n",
    "    'psych': b6_psychometric_response\n",
    "}\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    print(f\"Missing values in '{key}':\")\n",
    "    print(df.isna().sum())\n",
    "    print()  # for spacing between outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alcohol Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 69\n",
      "Responsive Num Occasions: 6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['metric'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponsive Num Occasions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb1_alcohol_self_response[b1_alcohol_self_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponsive\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m b1_alcohol_self_response\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mb1_alcohol_self_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgroup\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontrol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifference_drinks_occasions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponsive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_demo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['metric'] not found in axis\""
     ]
    }
   ],
   "source": [
    "print(f'Samples: {len(b1_alcohol_self_response)}')\n",
    "print(f'Responsive Num Occasions: {b1_alcohol_self_response[b1_alcohol_self_response[\"responsive\"] == 1][\"id\"].nunique()}')\n",
    "\n",
    "b1_alcohol_self_response.head()\n",
    "b1_alcohol_self_response.drop(columns=['group', 'condition', 'active', 'control', 'difference_drinks_occasions', 'metric', 'responsive']).to_csv('data_demo.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alcohol_self_response.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective_response.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective_response_old.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective_response.fillna(0)\n",
    "print(f'Samples: {len(b2_group_subjective_response)}')\n",
    "print(f'Responsive Num Occasions: {b2_group_subjective_response[b2_group_subjective_response[\"responsive\"] == 1][\"id\"].nunique()}')\n",
    "\n",
    "b2_group_subjective_response[['groupAtt_alc', 'groupAtt_binge']] = b2_group_subjective_response[['groupAtt_alc', 'groupAtt_binge']].astype(int)\n",
    "\n",
    "b2_group_subjective_response.head()\n",
    "# b2_group_subjective_response.drop(columns=['group', 'condition', 'active', 'control', 'difference_drinks_occasions', 'metric', 'responsive']).to_csv('data_demo.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Sociometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_group_sociometric_response.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bucket_response_psych.isna().sum()[bucket_response_psych.isna().sum() > 0])\n",
    "b3_group_sociometric_response = b3_group_sociometric_response.fillna(0)\n",
    "\n",
    "len(b3_group_sociometric_response)\n",
    "\n",
    "# Median imputation for NA values is handled in prepare_features_and_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_brain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_brain_response.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Samples: {len(b4_brain_response)}')\n",
    "print(f'Responsive Num Occasions: {b4_brain_response[b4_brain_response[\"responsive\"] == 1][\"id\"].nunique()}')\n",
    "\n",
    "len(b4_brain_response.columns)\n",
    "# b4_brain_response.drop(columns=['group', 'condition', 'active', 'control', 'difference_drinks_occasions', 'metric', 'responsive']).to_csv('data_brain.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find highly correlated features within buckets\n",
    "Find redundancy in features if they are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "    'demo': b5_demographic_response,\n",
    "    'psych': b6_psychometric_response\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective_response.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highly_correlated_features(dataframes, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Identifies pairs of highly correlated features in each dataframe.\n",
    "    :param dataframes: dict of {name: dataframe}\n",
    "    :param threshold: correlation threshold to consider as \"high\"\n",
    "    :return: dict of {name: list of correlated feature pairs}\n",
    "    \"\"\"\n",
    "    correlated_features = {}\n",
    "    for name, df in dataframes.items():\n",
    "        # Exclude COMMON_VARS from the correlation computation\n",
    "        columns_to_correlate = [col for col in df.columns if col not in COMMON_VARS]\n",
    "        \n",
    "        # Compute correlation matrix only for selected columns\n",
    "        corr_matrix = df[columns_to_correlate].corr().abs()\n",
    "        \n",
    "        # Select the upper triangle of the correlation matrix\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        \n",
    "        # Find pairs of features with correlation above the threshold\n",
    "        correlated_pairs = [\n",
    "            (col, idx, upper_triangle.loc[idx, col])\n",
    "            for col in upper_triangle.columns\n",
    "            for idx in upper_triangle.index\n",
    "            if upper_triangle.loc[idx, col] > threshold\n",
    "        ]\n",
    "        \n",
    "        # Store results for the current dataframe\n",
    "        correlated_features[name] = correlated_pairs\n",
    "\n",
    "    return correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = find_highly_correlated_features(dataframes, threshold=0.8)\n",
    "\n",
    "# Display results\n",
    "for name, pairs in correlated_features.items():\n",
    "    print(f\"\\n{name} - Highly Correlated Features:\")\n",
    "    for col1, col2, corr_value in pairs:\n",
    "        print(f\"  {col1} ↔ {col2} : Correlation = {corr_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove highly correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['brain'].drop(columns=['reward', 'ROI_alc_react_v_rest_neurosynth_cogcontrol', 'ROI_alc_react_v_rest_neurosynth_craving', \\\n",
    "                                  'ROI_alc_react_v_rest_neurosynth_emoreg'], inplace=True)\n",
    "\n",
    "dataframes['group_socio'].drop(columns=['leaders_deg_in', 'goToBad_deg_in'], inplace=True)\n",
    "\n",
    "dataframes['psych'].drop(columns=['ACS_focus', 'DERS_strategies', 'BIS_attention_total'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = find_highly_correlated_features(dataframes, threshold=0.8)\n",
    "\n",
    "# Display results\n",
    "for name, pairs in correlated_features.items():\n",
    "    print(f\"\\n{name} - Highly Correlated Features:\")\n",
    "    for col1, col2, corr_value in pairs:\n",
    "        print(f\"  {col1} ↔ {col2} : Correlation = {corr_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features\n",
    "{key: df.shape[1] for key, df in dataframes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_sub_old': b2_group_subjective_response_old,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "    'demo': b5_demographic_response,\n",
    "    'psych': b6_psychometric_response\n",
    "}\n",
    "\n",
    "target_var = 'responsive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5_demographic_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance tests: Features\n",
    "### Mann-Whitney U Tests\n",
    "\n",
    "Hypothesis test for non-normally distributed data to check which of the remaining features show the most (significant) difference between the two groups (responsive vs non-responsive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'responsive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_sub_old': b2_group_subjective_response_old,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "    'demo': b5_demographic_response,\n",
    "    'psych': b6_psychometric_response\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_mann_whitney_u(df, target_var, exclude_vars):\n",
    "    results = {}\n",
    "    for col in df.columns:\n",
    "        if col not in exclude_vars and col != target_var:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                group1 = df[df[target_var] == 0][col]\n",
    "                group2 = df[df[target_var] == 1][col]\n",
    "                stat, p_value = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "                results[col] = {'U_statistic': stat, 'p_value': p_value}\n",
    "            except Exception as e:\n",
    "                results[col] = {'error': str(e)}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_results = {}\n",
    "for name, df in dataframes.items():\n",
    "    if name != 'demo' and target_var in df.columns:\n",
    "        mwu_results[name] = perform_mann_whitney_u(df, target_var, EXCLUDE_VARS)\n",
    "\n",
    "# Output summary\n",
    "for name, results in mwu_results.items():\n",
    "    print(f\"\\n{name} DataFrame Mann-Whitney U Test Results (p-value < 0.05):\")\n",
    "    \n",
    "    # Ensure only variables with p-values < 0.05 are retained\n",
    "    significant_results = {}\n",
    "    for var, stats in results.items():\n",
    "        if isinstance(stats, dict) and 'p_value' in stats and stats['p_value'] < 0.05:\n",
    "            significant_results[var] = stats  \n",
    "    \n",
    "    if significant_results:\n",
    "        df_significant = pd.DataFrame(significant_results).T  \n",
    "        print(df_significant)\n",
    "    else:\n",
    "        print(\"No significant results (p-value < 0.05) found.\")\n",
    "\n",
    "    print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_features_and_targets(df, target_var, test_set=0, resampling=None):\n",
    "    if target_var not in df.columns:\n",
    "        raise ValueError(f\"Target variable '{target_var}' not found in dataframe.\")\n",
    "\n",
    "    # Extract target variable and drop excluded columns\n",
    "    targets = df[target_var]\n",
    "    features = df[[col for col in df.columns if col not in EXCLUDE_VARS]]\n",
    "    features = features.drop(columns=[target_var], errors='ignore')\n",
    "\n",
    "    # Split into training and test sets (STRATIFIED)\n",
    "    if test_set:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            features, targets, test_size=test_set, stratify=targets\n",
    "        )\n",
    "    else: \n",
    "        X_train = features\n",
    "        Y_train = targets\n",
    "        X_test = []\n",
    "        Y_test = []\n",
    "\n",
    "    # Median imputation for 'income_numeric' if it contains NA values\n",
    "    if 'income_numeric' in X_train.columns:\n",
    "        if X_train['income_numeric'].isna().any():\n",
    "            X_train['income_numeric'].fillna(X_train['income_numeric'].median(), inplace=True)\n",
    "        if isinstance(X_test, pd.DataFrame) and 'income_numeric' in X_test.columns and X_test['income_numeric'].isna().any():\n",
    "            X_test['income_numeric'].fillna(X_test['income_numeric'].median(), inplace=True)\n",
    "\n",
    "    if 'IAS_mean' in X_train.columns:\n",
    "        if X_train['IAS_mean'].isna().any():\n",
    "            X_train['IAS_mean'].fillna(X_train['IAS_mean'].median(), inplace=True)\n",
    "        if isinstance(X_test, pd.DataFrame) and 'IAS_mean' in X_test.columns and X_test['IAS_mean'].isna().any():\n",
    "            X_test['IAS_mean'].fillna(X_test['IAS_mean'].median(), inplace=True)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_kfold_grid_search(\n",
    "    X, Y, param_grid, k=5, CV_reps=1, eval_metric=['auc'], model_choice_metric='auc', \n",
    "    res_dir=\".\", model_type='rf', combo='alcohol'\n",
    "):\n",
    "\n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "\n",
    "    # Initialize variables to store the best model and scores\n",
    "    best_model = None\n",
    "    best_scores = None\n",
    "    best_params = None\n",
    "    best_model_choice_value = -np.inf  # Track the best model based on the chosen metric\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    for params in param_combinations:\n",
    "        current_params = dict(zip(param_names, params))\n",
    "\n",
    "        # Store all fold results\n",
    "        all_folds_metrics = {metric: [] for metric in eval_metric}\n",
    "\n",
    "        for train_index, test_index in kf.split(X, Y):  # k-fold cv split\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "            rep_metrics = {metric: [] for metric in eval_metric}  # Reset for each fold\n",
    "\n",
    "            for _ in range(CV_reps):  # Repeat that split j times\n",
    "\n",
    "                # Initialize the model with the current parameters\n",
    "                if model_type == 'rf':\n",
    "                    model = RandomForestClassifier(\n",
    "                        n_estimators=current_params.get(\"n_estimators\", 100),\n",
    "                        max_depth=current_params.get(\"max_depth\"),\n",
    "                        min_samples_split=current_params.get(\"min_samples_split\", 2),\n",
    "                        min_samples_leaf=current_params.get(\"min_samples_leaf\", 1),\n",
    "                        class_weight=\"balanced\"\n",
    "                    )\n",
    "                elif model_type == 'xgb':\n",
    "                    model = XGBClassifier(\n",
    "                        n_estimators=current_params.get(\"n_estimators\", 100),\n",
    "                        max_depth=current_params.get(\"max_depth\", 6),\n",
    "                        learning_rate=current_params.get(\"learning_rate\", 0.1),\n",
    "                        min_child_weight=current_params.get(\"min_child_weight\", 1),\n",
    "                        gamma=current_params.get(\"gamma\", 0),\n",
    "                        subsample=current_params.get(\"subsample\", 1),\n",
    "                        colsample_bytree=current_params.get(\"colsample_bytree\", 1),\n",
    "                        scale_pos_weight=current_params.get(\"scale_pos_weight\", 1),\n",
    "                        use_label_encoder=False,\n",
    "                        eval_metric=\"logloss\"\n",
    "                    )\n",
    "\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred = model.predict(X_test)\n",
    "                Y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "                if 'auc' in eval_metric and Y_prob is not None:\n",
    "                    rep_metrics['auc'].append(roc_auc_score(Y_test, Y_prob))\n",
    "                if 'f1' in eval_metric:\n",
    "                    rep_metrics['f1'].append(f1_score(Y_test, Y_pred))\n",
    "                if 'accuracy' in eval_metric:\n",
    "                    rep_metrics['accuracy'].append(accuracy_score(Y_test, Y_pred))\n",
    "                if 'specificity' in eval_metric or 'sensitivity' in eval_metric:\n",
    "                    tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "                    specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "                    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "                    if 'specificity' in eval_metric:\n",
    "                        rep_metrics['specificity'].append(specificity)\n",
    "                    if 'sensitivity' in eval_metric:\n",
    "                        rep_metrics['sensitivity'].append(sensitivity)\n",
    "                if 'mcc' in eval_metric:\n",
    "                    rep_metrics['mcc'].append(matthews_corrcoef(Y_test, Y_pred))\n",
    "                if 'balancedAcc' in eval_metric:\n",
    "                    rep_metrics['balancedAcc'].append(balanced_accuracy_score(Y_test, Y_pred))\n",
    "                if 'pr_auc' in eval_metric and Y_prob is not None:\n",
    "                    precision, recall, _ = precision_recall_curve(Y_test, Y_prob)\n",
    "                    pr_auc = auc(recall, precision)\n",
    "                    rep_metrics['pr_auc'].append(pr_auc)\n",
    "\n",
    "            # Compute median scores per fold and store results\n",
    "            fold_median_metrics = {metric: np.mean(values) for metric, values in rep_metrics.items()}\n",
    "            for metric in eval_metric:\n",
    "                all_folds_metrics[metric].append(fold_median_metrics[metric])\n",
    "\n",
    "        # Compute final median scores over all folds\n",
    "        median_rep_metrics = {metric: np.mean(values) for metric, values in all_folds_metrics.items()}\n",
    "\n",
    "        # Select best model based on median of model_choice_metric\n",
    "        if median_rep_metrics[model_choice_metric] > best_model_choice_value:\n",
    "            best_model_choice_value = median_rep_metrics[model_choice_metric]\n",
    "            best_model = model\n",
    "            best_params = current_params\n",
    "            best_scores = median_rep_metrics  # Store median scores for all metrics\n",
    "\n",
    "    return best_model, best_scores, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (f1_score, accuracy_score, matthews_corrcoef,\n",
    "                             balanced_accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def random_forest_loocv_grid_search(\n",
    "    X, Y, param_grid, CV_reps=1, eval_metric=['auc'], model_choice_metric='auc', \n",
    "    res_dir=\".\", model_type='rf', combo='alcohol'\n",
    "):\n",
    "    \n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    best_model = None\n",
    "    best_scores = None\n",
    "    best_params = None\n",
    "    best_model_choice_value = -np.inf  # Track the best model based on the chosen metric\n",
    "    last_trained_model = None  # Fallback model\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        current_params = dict(zip(param_grid.keys(), params))\n",
    "        \n",
    "        all_folds_metrics = {metric: [] for metric in eval_metric}\n",
    "        \n",
    "        # Precompute the LOOCV splits once to save time\n",
    "        splits = list(loo.split(X, Y))\n",
    "        \n",
    "        for _ in range(CV_reps):\n",
    "            all_Y_true = []\n",
    "            all_Y_prob = []\n",
    "            all_Y_pred = []\n",
    "            \n",
    "            for train_index, test_index in splits:\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "                \n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=current_params.get(\"n_estimators\", 100),\n",
    "                    max_depth=current_params.get(\"max_depth\"),\n",
    "                    min_samples_split=current_params.get(\"min_samples_split\", 2),\n",
    "                    min_samples_leaf=current_params.get(\"min_samples_leaf\", 1),\n",
    "                    class_weight=\"balanced\"\n",
    "                )\n",
    "                \n",
    "                model.fit(X_train, Y_train)\n",
    "                last_trained_model = model  # Store last trained model as fallback\n",
    "                Y_pred = model.predict(X_test)\n",
    "                Y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "                \n",
    "                all_Y_true.append(Y_test.iloc[0])\n",
    "                all_Y_pred.append(Y_pred[0])\n",
    "                all_Y_prob.append(Y_prob[0] if Y_prob is not None else Y_pred[0])\n",
    "            \n",
    "            fold_metrics = {}\n",
    "            if 'auc' in eval_metric and len(set(all_Y_true)) > 1:\n",
    "                fold_metrics['auc'] = roc_auc_score(all_Y_true, all_Y_prob)\n",
    "            if 'f1' in eval_metric:\n",
    "                fold_metrics['f1'] = f1_score(all_Y_true, all_Y_pred)\n",
    "            if 'accuracy' in eval_metric:\n",
    "                fold_metrics['accuracy'] = accuracy_score(all_Y_true, all_Y_pred)\n",
    "            if 'mcc' in eval_metric:\n",
    "                fold_metrics['mcc'] = matthews_corrcoef(all_Y_true, all_Y_pred)\n",
    "            if 'balancedAcc' in eval_metric:\n",
    "                fold_metrics['balancedAcc'] = balanced_accuracy_score(all_Y_true, all_Y_pred)\n",
    "            if 'specificity' in eval_metric or 'sensitivity' in eval_metric:\n",
    "                tn, fp, fn, tp = confusion_matrix(all_Y_true, all_Y_pred).ravel()\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "                if 'specificity' in eval_metric:\n",
    "                    fold_metrics['specificity'] = specificity\n",
    "                if 'sensitivity' in eval_metric:\n",
    "                    fold_metrics['sensitivity'] = sensitivity\n",
    "            \n",
    "            for metric in eval_metric:\n",
    "                all_folds_metrics[metric].append(fold_metrics.get(metric, np.nan))\n",
    "        \n",
    "        mean_fold_metrics = {metric: np.mean(values) for metric, values in all_folds_metrics.items()}\n",
    "        \n",
    "        if model_choice_metric in mean_fold_metrics and not np.isnan(mean_fold_metrics[model_choice_metric]):\n",
    "            if mean_fold_metrics[model_choice_metric] > best_model_choice_value:\n",
    "                best_model_choice_value = mean_fold_metrics[model_choice_metric]\n",
    "                best_model = model\n",
    "                best_params = current_params\n",
    "                best_scores = mean_fold_metrics  \n",
    "    \n",
    "    if best_model is None:\n",
    "        best_model = last_trained_model  # Use last trained model as a fallback\n",
    "    \n",
    "    return best_model, best_scores, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(results_dict, results_dir, filename):\n",
    "\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Define the output file path\n",
    "    file_path = os.path.join(results_dir, filename)\n",
    "    \n",
    "    # Extract all metric names\n",
    "    all_metrics = set()\n",
    "    for metrics in results_dict.values():\n",
    "        all_metrics.update(metrics.keys())\n",
    "    \n",
    "    # Sort metrics for consistency\n",
    "    all_metrics = sorted(all_metrics)\n",
    "\n",
    "    # Open CSV file for writing\n",
    "    with open(file_path, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write header\n",
    "        header = [\"run\", \"group\"] + all_metrics\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Write data\n",
    "        for group, metrics in results_dict.items():\n",
    "            num_runs = len(next(iter(metrics.values())))  # Get number of runs from first metric\n",
    "            for run_idx in range(num_runs):\n",
    "                row = [run_idx, str(group)]  # Start with run index and group name\n",
    "                for metric in all_metrics:\n",
    "                    value = metrics.get(metric, [np.nan] * num_runs)[run_idx]  # Handle missing values\n",
    "                    row.append(value)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_pdp(model, X, shap_values, feature_names):\n",
    "    \"\"\"\n",
    "    Generates a Partial Dependence Plot (PDP) with SHAP overlay for one feature\n",
    "    or a PDP interaction plot for two features.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Random Forest model.\n",
    "        X: Test data as a DataFrame.\n",
    "        shap_values: SHAP values (numpy array).\n",
    "        feature_names: A single feature (str) or two features (list of two).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure features exist\n",
    "    if isinstance(feature_names, str):\n",
    "        feature_names = [feature_names]  # Convert to list for consistency\n",
    "\n",
    "    for feature in feature_names:\n",
    "        if feature not in X.columns:\n",
    "            raise ValueError(f\"Feature '{feature}' not found in X\")\n",
    "\n",
    "    # Case 1: PDP for a single feature + SHAP overlay\n",
    "    if len(feature_names) == 1:\n",
    "        feature_name = feature_names[0]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # Side-by-side comparison\n",
    "\n",
    "        # PDP Plot\n",
    "        PartialDependenceDisplay.from_estimator(model, X, [feature_name], ax=axes[0])\n",
    "        axes[0].set_title(f\"PDP for {feature_name}\")\n",
    "\n",
    "        # Get SHAP values for the feature\n",
    "        feature_index = X.columns.get_loc(feature_name)\n",
    "        shap_feature_values = shap_values[:, feature_index]\n",
    "\n",
    "        # Overlay SHAP values on PDP\n",
    "        axes[0].scatter(X[feature_name], shap_feature_values, color='red', alpha=0.4, label=\"SHAP values\", s=20)\n",
    "        axes[0].legend()\n",
    "\n",
    "        # SHAP Dependence Plot\n",
    "        shap.dependence_plot(feature_name, shap_values, X, ax=axes[1], show=False)\n",
    "        axes[1].set_title(f\"SHAP Dependence Plot for {feature_name}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Case 2: PDP Interaction Plot for Two Features\n",
    "    elif len(feature_names) == 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # PDP Interaction Plot\n",
    "        PartialDependenceDisplay.from_estimator(model, X, [feature_names], ax=axes[0])\n",
    "        axes[0].set_title(f\"PDP Interaction: {feature_names[0]} & {feature_names[1]}\")\n",
    "\n",
    "        # SHAP Interaction Dependence Plot\n",
    "        shap.dependence_plot(feature_names[0], shap_values, X, interaction_index=feature_names[1], ax=axes[1], show=False)\n",
    "        axes[1].set_title(f\"SHAP Interaction Dependence: {feature_names[0]} & {feature_names[1]}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Only one or two feature names are supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def run_rf_train_test(dataframes, param_grid, eval_metrics, outer_reps=50, k=5, CV_reps=5, model_choice_metric='f1', \n",
    "                      res_dir=f\"./results/\", model_type='xgb', test_set=0.3, resampling=None, permutation=False):\n",
    "\n",
    "    timestamp = int(time.time())\n",
    "    res_dir = f\"{res_dir}/{timestamp}_{model_type}_outer{outer_reps}_cvrep{CV_reps}_k{k}_{model_choice_metric}_testsize{test_set}_resampling{resampling}_perm{permutation}/\"\n",
    "    os.makedirs(res_dir, exist_ok=True)\n",
    "    \n",
    "    keys = list(dataframes.keys())\n",
    "\n",
    "    # # Generate cumulative combinations: first, (first+second), (first+second+third), ..., all\n",
    "    # combinations_keys = [tuple(keys[:i]) for i in range(1, len(keys) + 1)]\n",
    "\n",
    "    # combo_validation_scores = {}\n",
    "    # combo_test_scores = {}\n",
    "\n",
    "    combinations_keys = list(chain.from_iterable(combinations(keys, r) for r in range(1, 3)))\n",
    "    combo_validation_scores = {}\n",
    "    combo_test_scores = {}\n",
    "    best_models = {} \n",
    "    best_shap_vals = {}\n",
    "    best_paramses = {}\n",
    "\n",
    "    all_val_scores = {}\n",
    "    all_test_scores = {}\n",
    "    all_models_sub = []\n",
    "\n",
    "    for combo in tqdm(combinations_keys):\n",
    "        validation_scores = {metric: [] for metric in eval_metrics}\n",
    "        test_scores = {metric: [] for metric in eval_metrics}\n",
    "        merged_df = dataframes[combo[0]].copy()\n",
    "        \n",
    "        for key in combo[1:]:\n",
    "            merged_df = merged_df.merge(dataframes[key].copy(), how='inner', on=COMMON_VARS)\n",
    "        if target_var not in merged_df.columns:\n",
    "            raise ValueError(f\"Target variable '{target_var}' not found in merged dataframe for combo: {combo}\")\n",
    "    \n",
    "        all_shap_values = []\n",
    "        all_test_data = []\n",
    "        best_overall_score = -np.inf \n",
    "        best_model_for_combo = None\n",
    "        best_params_for_combo = None\n",
    "        best_shap_for_combo = None\n",
    "\n",
    "        for _ in range(outer_reps): # i repetitions of train/test\n",
    "\n",
    "            # Prepare train/test split for this i (random & stratified)\n",
    "            X_data, Y_data, X_test, Y_test = prepare_features_and_targets(merged_df.copy(), target_var, test_set=test_set, resampling=resampling)\n",
    "\n",
    "            if permutation:\n",
    "                Y_data = Y_data.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "                Y_test = Y_test.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "                # print(f\"after_shuffle: {Y_data.head()}\")\n",
    "\n",
    "\n",
    "            # tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "            # tree.fit(X_data, Y_data)  # Train on features (X_data) and target (Y_data)\n",
    "\n",
    "            # importances = pd.Series(tree.feature_importances_, index=X_data.columns)  # Use X_data.columns\n",
    "            # print(\"Feature Importance:\", importances.sort_values(ascending=False).head(20))\n",
    "\n",
    "            if k=='loo':\n",
    "                best_model, best_scores, best_params = random_forest_loocv_grid_search(X_data, Y_data, \n",
    "                                                                                    param_grid, \n",
    "                                                                                    CV_reps=CV_reps, \n",
    "                                                                                    eval_metric=eval_metrics,\n",
    "                                                                                    model_choice_metric=model_choice_metric,\n",
    "                                                                                    res_dir=res_dir,\n",
    "                                                                                    model_type=model_type,\n",
    "                                                                                    combo=combo)\n",
    "            else:\n",
    "\n",
    "                best_model, best_scores, best_params = random_forest_kfold_grid_search(X_data, Y_data, \n",
    "                                                                                    param_grid, k=k, \n",
    "                                                                                    CV_reps=CV_reps, \n",
    "                                                                                    eval_metric=eval_metrics,\n",
    "                                                                                    model_choice_metric=model_choice_metric,\n",
    "                                                                                    res_dir=res_dir,\n",
    "                                                                                    model_type=model_type,\n",
    "                                                                                    combo=combo)\n",
    "            # collect metrics\n",
    "            for metric, score in best_scores.items():\n",
    "                validation_scores[metric].append(score)\n",
    "\n",
    "            # Retrain the best model on the full training dataset and evaluate on the test set\n",
    "            best_model.fit(X_data, Y_data)\n",
    "            test_predictions = best_model.predict(X_test)\n",
    "            proba_predictions = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            if model_type == 'rf':  \n",
    "                explainer = shap.TreeExplainer(best_model)\n",
    "                shap_values = explainer.shap_values(X_test) \n",
    "                shap_values = shap_values[:, :, 1]\n",
    "\n",
    "            else:\n",
    "                explainer = shap.TreeExplainer(best_model)\n",
    "                shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "            # Append SHAP values and test data for later aggregation\n",
    "            all_shap_values.append(shap_values)\n",
    "            all_test_data.append(pd.DataFrame(X_test))\n",
    "\n",
    "            if best_scores[model_choice_metric] > best_overall_score:\n",
    "                best_overall_score = best_scores[model_choice_metric]\n",
    "                best_model_for_combo = best_model\n",
    "                best_params_for_combo = best_params\n",
    "                best_shap_for_combo = shap_values  # Store SHAP values if needed\n",
    "\n",
    "            # Calculate and append metrics for the test set\n",
    "            test_scores['auc'].append(roc_auc_score(Y_test.ravel(), proba_predictions))\n",
    "            test_scores['f1'].append(f1_score(Y_test.ravel(), test_predictions))\n",
    "            test_scores['accuracy'].append(accuracy_score(Y_test.ravel(), test_predictions))\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(Y_test.ravel(), test_predictions).ravel()\n",
    "            test_scores['specificity'].append(tn / (tn + fp) if (tn + fp) > 0 else np.nan)\n",
    "            test_scores['sensitivity'].append(tp / (tp + fn) if (tp + fn) > 0 else np.nan)\n",
    "            test_scores['PPV'].append(tp / (tp + fp) if (tp + fp) > 0 else np.nan)\n",
    "            test_scores['NPV'].append(tn / (tn + fn) if (tn + fn) > 0 else np.nan)\n",
    "            test_scores['MCC'].append(matthews_corrcoef(Y_test.ravel(), test_predictions))\n",
    "            test_scores['balancedAcc'].append(balanced_accuracy_score(Y_test.ravel(), test_predictions))\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(Y_test.ravel(), proba_predictions)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            test_scores['pr_auc'].append(pr_auc)\n",
    "\n",
    "            test_scores['tn'].append(tn)\n",
    "            test_scores['fp'].append(fp)\n",
    "            test_scores['fn'].append(fn)\n",
    "            test_scores['tp'].append(tp)\n",
    "\n",
    "            if combo == ('group_sub',):\n",
    "                all_models_sub.append(best_model)\n",
    "\n",
    "        # Keep track of the best model based on the model_choice_metric\n",
    "        if combo not in best_models or best_scores[model_choice_metric] > combo_validation_scores[combo][model_choice_metric]['mean']:\n",
    "            best_models[combo] = best_model_for_combo\n",
    "            best_shap_vals[combo] = best_shap_for_combo\n",
    "            best_paramses[combo] = best_params_for_combo\n",
    "\n",
    "        # Combine SHAP values and test data\n",
    "        final_shap_values = np.vstack(all_shap_values)\n",
    "        final_test_data = pd.concat(all_test_data, ignore_index=True)\n",
    "\n",
    "        # Compute relative importance\n",
    "        mean_abs_shap = np.abs(final_shap_values).mean(axis=0)\n",
    "        rel_importance = 100 * mean_abs_shap / mean_abs_shap.sum()\n",
    "\n",
    "        # Plot SHAP summary without showing\n",
    "        plt.figure()\n",
    "        shap.summary_plot(final_shap_values, final_test_data, show=False, cmap='winter')\n",
    "\n",
    "        # Get current axis and y-tick labels\n",
    "        ax = plt.gca()\n",
    "        feature_names = [tick.get_text() for tick in ax.get_yticklabels()]\n",
    "\n",
    "        # Use Index.get_loc instead of list\n",
    "        col_index = final_test_data.columns\n",
    "        feature_order = [col_index.get_loc(name) for name in feature_names]\n",
    "\n",
    "        # Add percentage values\n",
    "        percent_labels = [f\"{name} ({rel_importance[i]:.1f}%)\" for name, i in zip(feature_names, feature_order)]\n",
    "        ax.set_yticklabels(percent_labels, fontsize=10)\n",
    "\n",
    "        # Save updated plot\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{res_dir}/{combo}_shap_summary_plot_with_percentages.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # Calculate mean and 95% CI for validation scores\n",
    "        z = norm.ppf(0.975)  # 95% confidence level\n",
    "        final_validation_scores = {}\n",
    "        for metric, scores in validation_scores.items():\n",
    "            mean_score = np.mean(scores)\n",
    "            std_error = np.std(scores, ddof=1) / np.sqrt(len(scores))\n",
    "            ci_lower = mean_score - z * std_error\n",
    "            ci_upper = mean_score + z * std_error\n",
    "            final_validation_scores[metric] = {\n",
    "                'mean': mean_score,\n",
    "                '95%_CI': (ci_lower, ci_upper)\n",
    "            }\n",
    "        combo_validation_scores[combo] = final_validation_scores\n",
    "        all_val_scores[combo] = validation_scores\n",
    "        save_metrics_to_csv(all_val_scores, res_dir, 'all_val_scores.csv')\n",
    "\n",
    "        # Calculate mean and 95% CI for test scores\n",
    "        final_test_scores = {}\n",
    "        for metric, scores in test_scores.items():\n",
    "            mean_score = np.mean(scores)\n",
    "            std_error = np.std(scores, ddof=1) / np.sqrt(len(scores))\n",
    "            ci_lower = mean_score - z * std_error\n",
    "            ci_upper = mean_score + z * std_error\n",
    "            final_test_scores[metric] = {\n",
    "                'mean': mean_score,\n",
    "                '95%_CI': (ci_lower, ci_upper)\n",
    "            }\n",
    "        combo_test_scores[combo] = final_test_scores\n",
    "        all_test_scores[combo] = test_scores\n",
    "        save_metrics_to_csv(all_test_scores, res_dir, 'all_test_scores.csv')\n",
    "\n",
    "\n",
    "        rows = []\n",
    "        # Iterate through the data and flatten it into rows\n",
    "        for combination, metrics in combo_test_scores.items():\n",
    "            row = {\"Combination\": combination}\n",
    "            for metric, values in metrics.items():\n",
    "                row[f\"{metric}_mean\"] = values[\"mean\"]\n",
    "                row[f\"{metric}_CI_lower\"] = values[\"95%_CI\"][0]\n",
    "                row[f\"{metric}_CI_upper\"] = values[\"95%_CI\"][1]\n",
    "            rows.append(row)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df_comb = pd.DataFrame(df[\"Combination\"].tolist(), columns=[f\"Factor_{i+1}\" for i in range(df[\"Combination\"].map(len).max())])\n",
    "        df = pd.concat([df_comb, df.drop(columns=\"Combination\")], axis=1)\n",
    "\n",
    "        rows = []\n",
    "        # Iterate through the data and flatten it into rows\n",
    "        for combination, metrics in combo_validation_scores.items():\n",
    "            row = {\"Combination\": combination}\n",
    "            for metric, values in metrics.items():\n",
    "                row[f\"{metric}_mean\"] = values[\"mean\"]\n",
    "                row[f\"{metric}_CI_lower\"] = values[\"95%_CI\"][0]\n",
    "                row[f\"{metric}_CI_upper\"] = values[\"95%_CI\"][1]\n",
    "            rows.append(row)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df_comb = pd.DataFrame(df[\"Combination\"].tolist(), columns=[f\"Factor_{i+1}\" for i in range(df[\"Combination\"].map(len).max())])\n",
    "        df = pd.concat([df_comb, df.drop(columns=\"Combination\")], axis=1)\n",
    "        df.to_csv(f\"{res_dir}/validation_scores.csv\")\n",
    "\n",
    "        rows = []\n",
    "        # Iterate through the data and flatten it into rows\n",
    "        for combination, metrics in combo_test_scores.items():\n",
    "            row = {\"Combination\": combination}\n",
    "            for metric, values in metrics.items():\n",
    "                row[f\"{metric}_mean\"] = values[\"mean\"]\n",
    "                row[f\"{metric}_CI_lower\"] = values[\"95%_CI\"][0]\n",
    "                row[f\"{metric}_CI_upper\"] = values[\"95%_CI\"][1]\n",
    "            rows.append(row)\n",
    "        df = pd.DataFrame(rows)\n",
    "        df_comb = pd.DataFrame(df[\"Combination\"].tolist(), columns=[f\"Factor_{i+1}\" for i in range(df[\"Combination\"].map(len).max())])\n",
    "        df = pd.concat([df_comb, df.drop(columns=\"Combination\")], axis=1)\n",
    "        df.to_csv(f\"{res_dir}/test_scores.csv\")\n",
    "\n",
    "        \n",
    "    return combo_validation_scores, combo_test_scores, validation_scores, test_scores, best_models, best_shap_vals, all_shap_values, all_test_data, all_models_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (confusion_matrix, roc_auc_score, f1_score, accuracy_score, \n",
    "                             recall_score, precision_score, matthews_corrcoef, balanced_accuracy_score)\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "def test_oos(test_df, best_model, best_params, plot=True):\n",
    "    # Define metrics\n",
    "    eval_metrics = ['auc', 'f1', 'accuracy', 'specificity', 'sensitivity', 'PPV', 'NPV', 'MCC', 'balancedAcc', 'pr_auc', 'tn', 'fn', 'tp', 'fp']\n",
    "    \n",
    "    # Drop common variables\n",
    "    test_features = test_df.drop(columns=COMMON_VARS + ['responsive'])\n",
    "    test_labels = test_df['responsive']\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = best_model.predict_proba(test_features)[:, 1]  # Probabilities for the positive class\n",
    "    y_pred = best_model.predict(test_features)\n",
    "    \n",
    "    # Compute metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(test_labels, y_pred).ravel()\n",
    "    \n",
    "    scores = {\n",
    "        'auc': roc_auc_score(test_labels, y_pred_proba),\n",
    "        'f1': f1_score(test_labels, y_pred),\n",
    "        'accuracy': accuracy_score(test_labels, y_pred),\n",
    "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else np.nan,\n",
    "        'sensitivity': recall_score(test_labels, y_pred),\n",
    "        'PPV': precision_score(test_labels, y_pred),\n",
    "        'NPV': tn / (tn + fn) if (tn + fn) > 0 else np.nan,\n",
    "        'MCC': matthews_corrcoef(test_labels, y_pred),\n",
    "        'balancedAcc': balanced_accuracy_score(test_labels, y_pred),\n",
    "        'pr_auc': roc_auc_score(test_labels, y_pred_proba),\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'tp': tp,\n",
    "        'fp': fp\n",
    "    }\n",
    "    \n",
    "    colors = [\"#22223B\", \"#4A4E69\", \"#9A8C98\", \"#C9ADA7\", \"#F2E9E4\"]\n",
    "\n",
    "    # SHAP feature importance\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(test_features)\n",
    "    shap_values = shap_values[:, :, 1]  # Extract SHAP values for positive class\n",
    "    \n",
    "    # Compute mean absolute SHAP values for importance ranking\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "    feature_importance = pd.DataFrame({'feature': test_features.columns, 'importance': shap_importance})\n",
    "    feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    if plot:\n",
    "        # Plot SHAP feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=feature_importance['importance'], y=feature_importance['feature'], color=colors[1])\n",
    "        plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.title(\"SHAP Feature Importance\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot SHAP summary\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(shap_values, test_features, show=False, cmap='winter')\n",
    "        plt.show()\n",
    "        \n",
    "        # PDP plots as subplots in one figure (including interaction plot)\n",
    "        top_features = feature_importance['feature'].head(2).tolist()\n",
    "        num_features = len(test_features.columns) + 1  # +1 for interaction plot\n",
    "        num_cols = 3  # Number of columns in subplot grid\n",
    "        num_rows = -(-num_features // num_cols)  # Ceiling division\n",
    "\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
    "        axes = axes.flatten()  # Flatten axes array for easy iteration\n",
    "\n",
    "        for idx, feature in enumerate(test_features.columns):\n",
    "            ax = axes[idx]\n",
    "            PartialDependenceDisplay.from_estimator(best_model, test_features, [feature], ax=ax, line_kw={\"color\": colors[1]})\n",
    "            ax.set_title(f'PDP for {feature}')\n",
    "\n",
    "        # Add PDP interaction plot in the last subplot\n",
    "        ax = axes[len(test_features.columns)]\n",
    "        PartialDependenceDisplay.from_estimator(best_model, test_features, [top_features], ax=ax, line_kw={\"color\": colors[1]})\n",
    "        ax.set_title(f'PDP Interaction: {top_features[0]} & {top_features[1]}')\n",
    "\n",
    "        # Hide unused subplots if any\n",
    "        for i in range(num_features, len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return scores, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def plot_explainability(best_model, all_shap_values, all_test_data):\n",
    "    \"\"\"\n",
    "    Generates:\n",
    "    - PDP plots with mean & standard deviation for all features, with a histogram below each PDP plot\n",
    "    - Feature Importance bar plot (SHAP)\n",
    "    - SHAP Summary plot\n",
    "    - SHAP Dependence plot for 'avg_alcmost_freq' and 'avg_alcmost'\n",
    "    - PDP Interaction plot for 'avg_alcmost_freq' and 'avg_alcmost'\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the color palette\n",
    "    colors = [\"#22223B\", \"#4A4E69\", \"#9A8C98\", \"#C9ADA7\", \"#F2E9E4\"]\n",
    "\n",
    "    # Aggregate SHAP values and test data\n",
    "    final_shap_values = np.vstack(all_shap_values)\n",
    "    final_test_data = pd.concat(all_test_data, ignore_index=True)\n",
    "    \n",
    "    # Compute SHAP feature importance\n",
    "    shap_importance = np.abs(final_shap_values).mean(axis=0)\n",
    "    feature_names = final_test_data.columns\n",
    "    \n",
    "    # Sort features by importance\n",
    "    sorted_indices = np.argsort(shap_importance)[::-1]\n",
    "    sorted_features = feature_names[sorted_indices]\n",
    "    sorted_importance = shap_importance[sorted_indices]\n",
    "\n",
    "    # Determine number of features including interaction plot\n",
    "    num_features = len(final_test_data.columns)\n",
    "    num_plots = num_features + 1  # Adding interaction plot\n",
    "    num_cols = 3  # Set number of columns for subplots\n",
    "    num_rows = -(-num_plots // num_cols)  # Compute rows (ceiling division)\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten axes array for easy indexing\n",
    "\n",
    "    # Loop over all features\n",
    "    for idx, feature_name in enumerate(final_test_data.columns):\n",
    "        pdp_values = []\n",
    "        feature_values_list = []\n",
    "\n",
    "        # Compute PDP for each run and store the results\n",
    "        for dat in all_test_data:\n",
    "            ax_dummy = plt.figure().add_subplot()  # Create dummy axis\n",
    "            ax_dummy.set_visible(False)\n",
    "\n",
    "            # Generate PDP without displaying it\n",
    "            pdp_display = PartialDependenceDisplay.from_estimator(best_model, dat, [feature_name], ax=ax_dummy)\n",
    "            plt.close(ax_dummy.figure)  # Close dummy figure\n",
    "\n",
    "            # Extract PDP values\n",
    "            pdp_x = pdp_display.lines_[0][0].get_xdata()\n",
    "            pdp_y = pdp_display.lines_[0][0].get_ydata()\n",
    "\n",
    "            pdp_values.append(pdp_y)\n",
    "            feature_values_list.append(pdp_x)\n",
    "\n",
    "        # Align all PDP curves to the same feature grid\n",
    "        common_feature_values = np.linspace(min(map(min, feature_values_list)), \n",
    "                                            max(map(max, feature_values_list)), \n",
    "                                            num=100)\n",
    "\n",
    "        interpolated_pdp_values = []\n",
    "        for i in range(len(pdp_values)):\n",
    "            f_interp = interp1d(feature_values_list[i], pdp_values[i], kind=\"linear\", fill_value=\"extrapolate\", color=colors[1])\n",
    "            interpolated_pdp_values.append(f_interp(common_feature_values))\n",
    "\n",
    "        # Convert to NumPy array for aggregation\n",
    "        pdp_values = np.array(interpolated_pdp_values)\n",
    "\n",
    "        # Compute mean and std\n",
    "        pdp_mean = np.mean(pdp_values, axis=0)\n",
    "        pdp_std = np.std(pdp_values, axis=0)\n",
    "\n",
    "        # Plot PDP in subplot\n",
    "        ax = axes[idx]\n",
    "        ax.plot(common_feature_values, pdp_mean, label=\"Mean PDP\", color=colors[0], lw=2)\n",
    "        ax.fill_between(common_feature_values, pdp_mean - pdp_std, pdp_mean + pdp_std, \n",
    "                        color=colors[2], alpha=0.5, label=\"Std Dev\")\n",
    "\n",
    "        # Labels and legend\n",
    "        ax.set_ylabel(\"Predicted Value\")\n",
    "        ax.set_title(f\"PDP for {feature_name}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Plot PDP Interaction for 'avg_alcmost_freq' and 'avg_alcmost'\n",
    "    ax_interaction = axes[num_features]  # Last subplot\n",
    "    PartialDependenceDisplay.from_estimator(best_model, final_test_data, \n",
    "                                            [(\"avg_alcmost_freq\", \"avg_alcmost\")], ax=ax_interaction)\n",
    "    ax_interaction.set_title(\"Interaction: avg_alcmost_freq & avg_alcmost\")\n",
    "\n",
    "    # Hide unused subplots if any\n",
    "    for i in range(num_features + 1, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Feature Importance Bar Plot\n",
    "    shap.summary_plot(final_shap_values, final_test_data, plot_type=\"bar\", color=colors[1])\n",
    "\n",
    "    # SHAP Summary Plot\n",
    "    shap.summary_plot(final_shap_values, final_test_data, cmap='winter')\n",
    "\n",
    "    # SHAP Dependence Plots\n",
    "    for feature in [\"avg_alcmost_freq\", \"avg_alcmost\"]:\n",
    "        shap.dependence_plot(feature, final_shap_values, final_test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'demo': b5_demographic_response,\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'psych': b6_psychometric_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "}\n",
    "\n",
    "# Get sets of unique IDs from each dataframe\n",
    "id_sets = [set(df[\"id\"].dropna().unique()) for df in dataframes.values()]\n",
    "\n",
    "# Find intersection of all ID sets\n",
    "common_ids = set.intersection(*id_sets)\n",
    "# Step 2: Filter demographic dataframe for those IDs and check who is responsive\n",
    "responsive_ids = b5_demographic_response[\n",
    "    (b5_demographic_response[\"id\"].isin(common_ids)) &\n",
    "    (b5_demographic_response[\"responsive\"] == 1)\n",
    "][\"id\"].nunique()\n",
    "\n",
    "print(f\"Number of responsive IDs present in all dataframes: {responsive_ids}\")\n",
    "\n",
    "# Print result\n",
    "print(f\"Number of unique IDs present in all dataframes: {len(common_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_brain_response.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_samples_split\": [2, 4, 8],\n",
    "    \"min_samples_leaf\": [2, 3, 5]\n",
    "}\n",
    "\n",
    "eval_metrics = ['auc', 'f1', 'accuracy', 'specificity', 'sensitivity', 'PPV', 'NPV', 'MCC', 'balancedAcc', 'pr_auc', 'tn', 'fn', 'tp', 'fp']\n",
    "\n",
    "permutation_tests = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model_k2, best_params_k2, all_shap_values_k2, all_test_data_k2 = run_rf_train_test(dataframes, \n",
    "#                                                                                                 param_grid, \n",
    "#                                                                                                 eval_metrics, \n",
    "#                                                                                                 outer_reps=100,\n",
    "#                                                                                                 k=2, \n",
    "#                                                                                                 CV_reps=5, \n",
    "#                                                                                                 model_choice_metric='auc', \n",
    "#                                                                                                 res_dir=f\"./results_finalbuckets/\", \n",
    "#                                                                                                 model_type='rf', \n",
    "#                                                                                                 test_set=0.3, \n",
    "#                                                                                                 resampling=None,\n",
    "#                                                                                                 permutation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores, best_params = test_oos(b2_group_subjective_test, best_model_k2[('group_sub',)], best_model_k2[('group_sub',)])\n",
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if permutation_tests:\n",
    "#     combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model, best_params, all_shap_values, all_test_data = run_rf_train_test(dataframes, \n",
    "#                                                                                                 param_grid, \n",
    "#                                                                                                 eval_metrics, \n",
    "#                                                                                                 outer_reps=100, \n",
    "#                                                                                                 k=2, \n",
    "#                                                                                                 CV_reps=5, \n",
    "#                                                                                                 model_choice_metric='auc', \n",
    "#                                                                                                 res_dir=f\"./results_finalbuckets/\", \n",
    "#                                                                                                 model_type='rf', \n",
    "#                                                                                                 test_set=0.3, \n",
    "#                                                                                                 resampling=None,\n",
    "#                                                                                                 permutation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = {\n",
    "#     'group_sub': b2_group_subjective_response,\n",
    "# }\n",
    "\n",
    "dataframes = {\n",
    "    'demo': b5_demographic_response,\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'psych': b6_psychometric_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "}\n",
    "\n",
    "combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model_k3, best_shaps_k3, all_shap_values_k3, all_test_data_k3 = run_rf_train_test(dataframes, \n",
    "                                                                                                param_grid, \n",
    "                                                                                                eval_metrics, \n",
    "                                                                                                outer_reps=100, \n",
    "                                                                                                k=3, \n",
    "                                                                                                CV_reps=5, \n",
    "                                                                                                model_choice_metric='auc', \n",
    "                                                                                                res_dir=f\"./results_finalbuckets/\", \n",
    "                                                                                                model_type='rf', \n",
    "                                                                                                test_set=0.3, \n",
    "                                                                                                resampling=None,\n",
    "                                                                                                permutation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = {\n",
    "#     'group_sub': b2_group_subjective_response,\n",
    "# }\n",
    "\n",
    "dataframes = {\n",
    "    # 'demo': b5_demographic_response,\n",
    "    # 'alc_self': b1_alcohol_self_response,\n",
    "    # 'psych': b6_psychometric_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    # 'group_socio': b3_group_sociometric_response,\n",
    "    # 'brain': b4_brain_response,\n",
    "}\n",
    "\n",
    "combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model_k3, best_shaps_k3, all_shap_values_k3, all_test_data_k3, \\\n",
    "    all_models_sub = run_rf_train_test(dataframes, \n",
    "                                                                                                param_grid, \n",
    "                                                                                                eval_metrics, \n",
    "                                                                                                outer_reps=100, \n",
    "                                                                                                k=3, \n",
    "                                                                                                CV_reps=5, \n",
    "                                                                                                model_choice_metric='auc', \n",
    "                                                                                                res_dir=f\"./results_finalbuckets/\", \n",
    "                                                                                                model_type='rf', \n",
    "                                                                                                test_set=0.3, \n",
    "                                                                                                resampling=None,\n",
    "                                                                                                permutation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP/Feat importance for the full train/validation data\n",
    "\n",
    "# plot_explainability(best_model_k3[('group_sub',)], all_shap_values_k3, all_test_data_k3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance and SHAP summary for the best model and its validation set\n",
    "\n",
    "colors = [\"#22223B\", \"#4A4E69\", \"#9A8C98\", \"#C9ADA7\", \"#F2E9E4\"]\n",
    "\n",
    "# Extract SHAP values, model, and test data\n",
    "shap_values_dict, model_dict, all_test_data_k3 = best_shaps_k3, best_model_k3, all_test_data_k3\n",
    "\n",
    "# Extract key (e.g., 'group_sub') and associated SHAP values and model\n",
    "key = list(shap_values_dict.keys())[0]\n",
    "shap_values = shap_values_dict[key]  # SHAP values\n",
    "model = model_dict[key]  # RandomForest model\n",
    "\n",
    "# Ensure all_test_data_k3 is a DataFrame (if it's a list, extract first element)\n",
    "if isinstance(all_test_data_k3, list):\n",
    "    all_test_data_k3 = all_test_data_k3[0]  # Extract DataFrame\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = all_test_data_k3.columns.to_numpy()\n",
    "\n",
    "# Extract actual feature dataset (X_test) for SHAP summary plot\n",
    "X_test = all_test_data_k3.to_numpy()  # Convert DataFrame to numpy array if needed\n",
    "\n",
    "# Compute feature importance from the Random Forest model\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Ensure alignment between feature names and importances\n",
    "sorted_indices = np.argsort(feature_importance)\n",
    "feature_importance_sorted = feature_importance[sorted_indices]\n",
    "feature_names_sorted = feature_names[sorted_indices]\n",
    "\n",
    "# Plot Feature Importance (Random Forest)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=feature_importance_sorted, y=feature_names_sorted, color=colors[1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Convert SHAP values to array (if not already)\n",
    "shap_values_array = np.array(shap_values)\n",
    "\n",
    "# SHAP Summary Plot WITH Feature Values\n",
    "shap.summary_plot(shap_values_array, X_test, feature_names=feature_names, cmap='winter')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for distribution of the GRP features\n",
    "\n",
    "# Define color scheme\n",
    "colors = [\"#22223B\", \"#4A4E69\", \"#9A8C98\", \"#C9ADA7\", \"#F2E9E4\"]\n",
    "\n",
    "# Define features and bin settings\n",
    "features = {\n",
    "    \"avg_alcmost_freq\": (range(0, 110, 10), colors[2]),  # 1-100, bins of 10\n",
    "    \"avg_alcmost\": (np.arange(0, 22.5, 1), colors[2]),  # 1-20, bins of 2.5\n",
    "    \"alc_norm_5_r\": (range(1, 7, 1), colors[2]),  # 1-5, bins of 1\n",
    "    \"groupAtt_alc\": (range(1, 7, 1), colors[2]),  # 1-5, bins of 1\n",
    "    \"groupAtt_binge\": (range(1, 7, 1), colors[2]),  # 1-5, bins of 1\n",
    "}\n",
    "\n",
    "# Determine the number of features\n",
    "num_features = len(features)\n",
    "num_cols = 2  # Set to two columns\n",
    "num_rows = (num_features + num_cols - 1) // num_cols  # Calculate required rows\n",
    "\n",
    "# Create histograms\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, num_rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (feature, (bins, color)) in enumerate(features.items()):\n",
    "    axes[i].hist(b2_group_subjective_response[feature].dropna(), bins=bins, color=color, edgecolor=colors[1])\n",
    "    axes[i].set_title(feature)\n",
    "    axes[i].set_xlabel(\"Value\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of sample testing\n",
    "\n",
    "scores, best_params = test_oos(b2_group_subjective_test, best_model_k3[('group_sub',)], best_model_k3[('group_sub',)])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b2_group_subjective_test)\n",
    "b2_group_subjective_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_group_subjective.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat resample / stratification of the test\n",
    "import scipy.stats as st\n",
    "\n",
    "b2_group_subjective_test.dropna()\n",
    "# Define number of iterations\n",
    "n_iterations = 100\n",
    "desired_positive_rate = 0.24  # Ensure 23% positive class\n",
    "\n",
    "# Separate positive and negative cases once\n",
    "positive_cases = b2_group_subjective_test[b2_group_subjective_test['responsive'] == 1]\n",
    "negative_cases = b2_group_subjective_test[b2_group_subjective_test['responsive'] == 0]\n",
    "\n",
    "# Store results\n",
    "all_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Recalculate the target positive count each iteration\n",
    "    total_samples = len(b2_group_subjective_test)  # Keep dataset size unchanged\n",
    "    target_positive_count = int(total_samples * desired_positive_rate)\n",
    "    target_negative_count = total_samples - target_positive_count  # Adjust negatives\n",
    "\n",
    "    # Resample positives and negatives\n",
    "    positive_resampled = resample(positive_cases, replace=True, n_samples=target_positive_count, random_state=None)\n",
    "    negative_resampled = resample(negative_cases, replace=False, n_samples=target_negative_count, random_state=None)\n",
    "\n",
    "    # Create balanced dataset\n",
    "    balanced_df = pd.concat([positive_resampled, negative_resampled])\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "\n",
    "    # Run the model and store scores\n",
    "    scores, best_params = test_oos(balanced_df, best_model_k3[('group_sub',)], [], plot=False)\n",
    "    print(balanced_df.responsive.sum() / len(balanced_df))\n",
    "    all_scores.append(scores)\n",
    "\n",
    "# Convert to DataFrame\n",
    "scores_df = pd.DataFrame(all_scores)\n",
    "\n",
    "# Compute mean and 95% CI for each metric\n",
    "mean_scores = scores_df.mean()\n",
    "ci_lower, ci_upper = st.t.interval(0.95, df=n_iterations-1, loc=mean_scores, scale=scores_df.sem())\n",
    "\n",
    "# Combine into a DataFrame for better visualization\n",
    "summary_df = pd.DataFrame({'Mean': mean_scores, '95% CI Lower': ci_lower, '95% CI Upper': ci_upper})\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load and filter for group_sub\n",
    "df = pd.read_csv(\"/Users/fmagdalena/Documents/GitHub/shine-network-analysis/src/responsiveness/results_finalbuckets/1744295312_rf_outer100_cvrep5_k3_auc_testsize0.3_resamplingNone_permFalse/all_test_scores.csv\")\n",
    "group_name = \"('group_sub',)\"\n",
    "group_df = df[df['group'] == group_name]\n",
    "\n",
    "# Select top 10 models based on AUC\n",
    "top_indices = group_df['auc'].nlargest(5).index.tolist()\n",
    "top_models_sub = [all_models_sub[i] for i in top_indices]\n",
    "\n",
    "# Prepare test set\n",
    "b2_group_subjective_test = b2_group_subjective_test.dropna()\n",
    "\n",
    "# Define number of iterations and target positive rate\n",
    "n_iterations = 50\n",
    "desired_positive_rate = 0.24\n",
    "\n",
    "# Pre-separate positive and negative cases\n",
    "positive_cases = b2_group_subjective_test[b2_group_subjective_test['responsive'] == 1]\n",
    "negative_cases = b2_group_subjective_test[b2_group_subjective_test['responsive'] == 0]\n",
    "\n",
    "# Store all scores\n",
    "all_scores = []\n",
    "\n",
    "# Loop over each top model and perform resampling/testing\n",
    "for model in tqdm(top_models_sub, desc=\"Running top models\"):\n",
    "    for _ in range(n_iterations):\n",
    "        # Stratified sampling\n",
    "        total_samples = len(b2_group_subjective_test)\n",
    "        target_positive_count = int(total_samples * desired_positive_rate)\n",
    "        target_negative_count = total_samples - target_positive_count\n",
    "\n",
    "        positive_resampled = resample(positive_cases, replace=True, n_samples=target_positive_count, random_state=None)\n",
    "        negative_resampled = resample(negative_cases, replace=False, n_samples=target_negative_count, random_state=None)\n",
    "\n",
    "        balanced_df = pd.concat([positive_resampled, negative_resampled])\n",
    "        balanced_df = balanced_df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "\n",
    "        # Test model\n",
    "        scores, _ = test_oos(balanced_df, model, [], plot=False)\n",
    "        all_scores.append(scores)\n",
    "\n",
    "# Convert to DataFrame\n",
    "scores_df = pd.DataFrame(all_scores)\n",
    "\n",
    "# Compute mean and 95% CI\n",
    "mean_scores = scores_df.mean()\n",
    "ci_lower, ci_upper = st.t.interval(0.95, df=len(scores_df)-1, loc=mean_scores, scale=scores_df.sem())\n",
    "\n",
    "# Create summary\n",
    "summary_df = pd.DataFrame({'Mean': mean_scores, '95% CI Lower': ci_lower, '95% CI Upper': ci_upper})\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if permutation_tests:\n",
    "    combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model, best_params, all_shap_values, all_test_data = run_rf_train_test(dataframes, \n",
    "                                                                                                param_grid, \n",
    "                                                                                                eval_metrics, \n",
    "                                                                                                outer_reps=100, \n",
    "                                                                                                k=3, \n",
    "                                                                                                CV_reps=5, \n",
    "                                                                                                model_choice_metric='auc', \n",
    "                                                                                                res_dir=f\"./results_finalbuckets/\", \n",
    "                                                                                                model_type='rf', \n",
    "                                                                                                test_set=0.3, \n",
    "                                                                                                resampling=None,\n",
    "                                                                                                permutation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normal Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model_k5, best_params_k5, all_shap_values_k5, all_test_data_k5 = run_rf_train_test(dataframes, \n",
    "                                                                                                param_grid, \n",
    "                                                                                                eval_metrics, \n",
    "                                                                                                outer_reps=100, \n",
    "                                                                                                k=5, \n",
    "                                                                                                CV_reps=5, \n",
    "                                                                                                model_choice_metric='auc', \n",
    "                                                                                                res_dir=f\"./results_finalbuckets/\", \n",
    "                                                                                                model_type='rf', \n",
    "                                                                                                test_set=0.3, \n",
    "                                                                                                resampling=None,\n",
    "                                                                                                permutation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores, best_params = test_oos(b2_group_subjective_test, best_model[('group_sub',)], best_model[('group_sub',)])\n",
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if permutation_tests:\n",
    "    combo_validation_scores, combo_test_scores, all_val_scores, all_test_scores, best_model, best_params, all_shap_values, all_test_data = run_rf_train_test(dataframes, \n",
    "                                                                                                param_grid, \n",
    "                                                                                                eval_metrics, \n",
    "                                                                                                outer_reps=50, \n",
    "                                                                                                k=5, \n",
    "                                                                                                CV_reps=3, \n",
    "                                                                                                model_choice_metric='auc', \n",
    "                                                                                                res_dir=f\"./results_finalbuckets/\", \n",
    "                                                                                                model_type='rf', \n",
    "                                                                                                test_set=0.3, \n",
    "                                                                                                resampling=None,\n",
    "                                                                                                permutation=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
